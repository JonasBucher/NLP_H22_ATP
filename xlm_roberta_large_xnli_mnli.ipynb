{"cells":[{"cell_type":"markdown","metadata":{"id":"tE09a81yjGlU"},"source":["xlm_roberta_large_xnli modell <br>\n","submission to kaggle: load submissions and return it, kaggle needs a submission code which returns a submission.csv file"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":23530,"status":"ok","timestamp":1671545863893,"user":{"displayName":"Dominik Bieri","userId":"16263014991290198195"},"user_tz":-60},"id":"vQ7KIMVrqfi6","outputId":"2761be41-b8d2-4211-c6cb-6fba1d6beeed"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: sentencepiece in /usr/local/lib/python3.8/dist-packages (0.1.97)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: torch in /usr/local/lib/python3.8/dist-packages (1.13.0+cu116)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.8/dist-packages (0.14.0+cu116)\n","Requirement already satisfied: torchaudio in /usr/local/lib/python3.8/dist-packages (0.13.0+cu116)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch) (4.4.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from torchvision) (1.21.6)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.8/dist-packages (from torchvision) (7.1.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from torchvision) (2.23.0)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision) (1.25.11)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision) (2022.12.7)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (1.3.5)\n","Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.8/dist-packages (from pandas) (1.21.6)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas) (2.8.2)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas) (2022.6)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (1.21.6)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.8/dist-packages (1.0.2)\n","Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn) (1.7.3)\n","Requirement already satisfied: numpy>=1.14.6 in /usr/local/lib/python3.8/dist-packages (from scikit-learn) (1.21.6)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.8/dist-packages (from scikit-learn) (1.2.0)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn) (3.1.0)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: transformers in /usr/local/lib/python3.8/dist-packages (4.25.1)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (21.3)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.8.2)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.10.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (0.11.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2022.6.2)\n","Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (0.13.2)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers) (4.64.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (1.21.6)\n","Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.4.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2022.12.7)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (1.25.11)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2.10)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: datasets in /usr/local/lib/python3.8/dist-packages (2.8.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from datasets) (1.21.6)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from datasets) (6.0)\n","Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.8/dist-packages (from datasets) (4.64.1)\n","Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.8/dist-packages (from datasets) (0.18.0)\n","Requirement already satisfied: huggingface-hub<1.0.0,>=0.2.0 in /usr/local/lib/python3.8/dist-packages (from datasets) (0.11.1)\n","Requirement already satisfied: dill<0.3.7 in /usr/local/lib/python3.8/dist-packages (from datasets) (0.3.6)\n","Requirement already satisfied: multiprocess in /usr/local/lib/python3.8/dist-packages (from datasets) (0.70.14)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.8/dist-packages (from datasets) (2.23.0)\n","Requirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.8/dist-packages (from datasets) (2022.11.0)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.8/dist-packages (from datasets) (3.8.3)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from datasets) (1.3.5)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.8/dist-packages (from datasets) (3.1.0)\n","Requirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.8/dist-packages (from datasets) (9.0.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from datasets) (21.3)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (22.1.0)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (1.8.2)\n","Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (2.1.1)\n","Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (4.0.2)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (1.3.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (6.0.3)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (1.3.3)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets) (3.8.2)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets) (4.4.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->datasets) (3.0.9)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets) (1.25.11)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets) (2022.12.7)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas->datasets) (2022.6)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n"]}],"source":["!pip install sentencepiece\n","!pip3 install torch torchvision torchaudio\n","!pip install pandas\n","!pip install numpy\n","!pip install scikit-learn\n","!pip install transformers\n","!pip install datasets"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4125,"status":"ok","timestamp":1671545868015,"user":{"displayName":"Dominik Bieri","userId":"16263014991290198195"},"user_tz":-60},"id":"gAPixMnltm20","outputId":"044389c2-69e2-4ba1-c6ff-93d53a466511"},"outputs":[{"output_type":"stream","name":"stdout","text":["1.13.0+cu116\n"]}],"source":["import pandas as pd\n","import numpy as np\n","import os\n","import gc\n","\n","import random\n","\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","from torch.utils.data import Dataset, DataLoader\n","\n","# set a seed value\n","torch.manual_seed(555)\n","\n","from sklearn.utils import shuffle\n","from sklearn.metrics import roc_auc_score, accuracy_score\n","\n","import transformers\n","from transformers import AutoTokenizer, XLMRobertaForSequenceClassification\n","from transformers import AdamW\n","\n","from datasets import load_dataset\n","\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n","\n","\n","print(torch.__version__)"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":18,"status":"ok","timestamp":1671545868016,"user":{"displayName":"Dominik Bieri","userId":"16263014991290198195"},"user_tz":-60},"id":"7jv2ekewtm22","outputId":"189548aa-4a3b-4b97-9206-33fc3b76e301"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["12"]},"metadata":{},"execution_count":3}],"source":["MODEL_TYPE = 'joeddav/xlm-roberta-large-xnli'\n","\n","\n","L_RATE = 1e-5\n","MAX_LEN = 256\n","\n","NUM_EPOCHS = 5\n","BATCH_SIZE = 32\n","NUM_CORES = os.cpu_count()\n","\n","NUM_CORES"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12,"status":"ok","timestamp":1671545868016,"user":{"displayName":"Dominik Bieri","userId":"16263014991290198195"},"user_tz":-60},"id":"P_vSpen8tm22","outputId":"dae87a37-26d5-4fe5-87bd-2b175106e3d9"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["device(type='cuda', index=0)"]},"metadata":{},"execution_count":4}],"source":["device = torch.device('cuda:0')\n","device"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2072,"status":"ok","timestamp":1671545870079,"user":{"displayName":"Dominik Bieri","userId":"16263014991290198195"},"user_tz":-60},"id":"A2PZE-SvuDT5","outputId":"97fa6978-deea-46cc-d82b-b19fa41c2694"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12,"status":"ok","timestamp":1671545870079,"user":{"displayName":"Dominik Bieri","userId":"16263014991290198195"},"user_tz":-60},"id":"6XvCwc2vtm23","outputId":"2c52f2e2-27aa-4504-9045-85d3b008f437"},"outputs":[{"output_type":"stream","name":"stdout","text":["(10908, 6)\n"]}],"source":["df_train=pd.read_csv(\"drive/MyDrive/NLP_Project/data/train.csv\")\n","df_val=pd.read_csv(\"drive/MyDrive/NLP_Project/data/valid.csv\")\n","df_test=pd.read_csv(\"drive/MyDrive/NLP_Project/data/test.csv\")\n","\n","print(df_train.shape)"]},{"cell_type":"markdown","metadata":{"id":"eFWJzpt8nSfR"},"source":["### Load mnli data"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":273,"referenced_widgets":["3b1bacb8419c498d854d020c79847cc6","c83fce16b6214a5bbc79385f03961e5d","e9e4f6ab9e364a2d9a61b784ecf52806","8b2b05f0e4a743e7b67fd6e817eb3a5f","7fb4ad8c04c942ee81a4c462e29ba9f0","59db2e01f17f4736b16b2a4d61253d59","c361381b324841e694dfcc68df691998","25f3146c716d4c939540347cbf5eb73e","1c09cfb3782c4d51a3a65e88f23c664f","3d59e937083441c5b1f2592cd75ca9d4","dffd536873e04a3b915f816b2a322d66"]},"executionInfo":{"elapsed":18567,"status":"ok","timestamp":1671545888643,"user":{"displayName":"Dominik Bieri","userId":"16263014991290198195"},"user_tz":-60},"id":"2cl52eXqjO4A","outputId":"bb68e881-82c5-4d4e-819e-36006ae9a1a1"},"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:datasets.builder:Found cached dataset glue (/root/.cache/huggingface/datasets/glue/mnli/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/5 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3b1bacb8419c498d854d020c79847cc6"}},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["                                             premise  \\\n","0  Conceptually cream skimming has two basic dime...   \n","1  you know during the season and i guess at at y...   \n","2  One of our number will carry out your instruct...   \n","3  How do you know? All this is their information...   \n","4  yeah i tell you what though if you go price so...   \n","\n","                                          hypothesis  label  \n","0  Product and geography are what make cream skim...      1  \n","1  You lose the things to the following level if ...      0  \n","2  A member of my team will execute your orders w...      0  \n","3                  This information belongs to them.      0  \n","4           The tennis shoes have a range of prices.      1  "],"text/html":["\n","  <div id=\"df-3abbae67-bdd5-435d-8006-705b7efd0991\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>premise</th>\n","      <th>hypothesis</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Conceptually cream skimming has two basic dime...</td>\n","      <td>Product and geography are what make cream skim...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>you know during the season and i guess at at y...</td>\n","      <td>You lose the things to the following level if ...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>One of our number will carry out your instruct...</td>\n","      <td>A member of my team will execute your orders w...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>How do you know? All this is their information...</td>\n","      <td>This information belongs to them.</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>yeah i tell you what though if you go price so...</td>\n","      <td>The tennis shoes have a range of prices.</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3abbae67-bdd5-435d-8006-705b7efd0991')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-3abbae67-bdd5-435d-8006-705b7efd0991 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-3abbae67-bdd5-435d-8006-705b7efd0991');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":7}],"source":["mnli = load_dataset('glue', 'mnli')\n","df_mlni = pd.DataFrame.from_dict(mnli[\"train\"])\n","df_mlni.drop(columns=['idx'], inplace=True)\n","df_mlni.head()"]},{"cell_type":"code","source":["mnli"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"s4TWKWY11qK-","executionInfo":{"status":"ok","timestamp":1671545888643,"user_tz":-60,"elapsed":10,"user":{"displayName":"Dominik Bieri","userId":"16263014991290198195"}},"outputId":"df65ebf5-facc-4bc7-b144-efda2af6edab"},"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/plain":["DatasetDict({\n","    train: Dataset({\n","        features: ['premise', 'hypothesis', 'label', 'idx'],\n","        num_rows: 392702\n","    })\n","    validation_matched: Dataset({\n","        features: ['premise', 'hypothesis', 'label', 'idx'],\n","        num_rows: 9815\n","    })\n","    validation_mismatched: Dataset({\n","        features: ['premise', 'hypothesis', 'label', 'idx'],\n","        num_rows: 9832\n","    })\n","    test_matched: Dataset({\n","        features: ['premise', 'hypothesis', 'label', 'idx'],\n","        num_rows: 9796\n","    })\n","    test_mismatched: Dataset({\n","        features: ['premise', 'hypothesis', 'label', 'idx'],\n","        num_rows: 9847\n","    })\n","})"]},"metadata":{},"execution_count":8}]},{"cell_type":"code","source":["df_mnli = pd.DataFrame.from_dict(mnli[\"validation_matched\"])\n","df_mnli.drop(columns=['idx'], inplace=True)\n","df_mnli.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xG4J4J8l2aXZ","executionInfo":{"status":"ok","timestamp":1671545888952,"user_tz":-60,"elapsed":314,"user":{"displayName":"Dominik Bieri","userId":"16263014991290198195"}},"outputId":"ae8ad24e-b94a-430a-ba7c-08ccfd22cf5b"},"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(9815, 3)"]},"metadata":{},"execution_count":9}]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1671545888952,"user":{"displayName":"Dominik Bieri","userId":"16263014991290198195"},"user_tz":-60},"id":"A4RsW1R7nWrP"},"outputs":[],"source":["df_mnli['label'] = df_mnli['label'].replace([0, 2], [2, 0])       # because 0, 2 are changed in training of xlm_roberta_large_xnli\n","df_val['label'] = df_val['label'].replace([0, 2], [2, 0])                     # because 0, 2 are changed in training of xlm_roberta_large_xnli"]},{"cell_type":"markdown","metadata":{"id":"LpWdAlqhnb6C"},"source":["### Load Tokenizer"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1209,"status":"ok","timestamp":1671545890158,"user":{"displayName":"Dominik Bieri","userId":"16263014991290198195"},"user_tz":-60},"id":"o5Srx7KAtm23","outputId":"cd7db358-2a80-4ea5-e7bd-d6a800130666"},"outputs":[{"output_type":"stream","name":"stdout","text":["Loading Roberta tokenizer...\n"]}],"source":["print('Loading Roberta tokenizer...')\n","tokenizer = AutoTokenizer.from_pretrained(MODEL_TYPE)"]},{"cell_type":"code","execution_count":12,"metadata":{"executionInfo":{"elapsed":9,"status":"ok","timestamp":1671545890159,"user":{"displayName":"Dominik Bieri","userId":"16263014991290198195"},"user_tz":-60},"id":"WGYLtM_ftm23"},"outputs":[],"source":["df_val = df_val.reset_index(drop=True)\n","df_train_mnli = df_mnli.reset_index(drop=True)"]},{"cell_type":"code","execution_count":13,"metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1671545890159,"user":{"displayName":"Dominik Bieri","userId":"16263014991290198195"},"user_tz":-60},"id":"Swhu9epptm24"},"outputs":[],"source":["class CompDataset(Dataset):\n","\n","    def __init__(self, df):\n","        self.df_data = df\n","\n","\n","\n","    def __getitem__(self, index):\n","\n","        # get the sentence from the dataframe\n","        sentence1 = self.df_data.loc[index, 'premise']\n","        sentence2 = self.df_data.loc[index, 'hypothesis']\n","\n","        # Process the sentence\n","        # ---------------------\n","\n","        encoded_dict = tokenizer.encode_plus(\n","                    sentence1, sentence2,           # Sentences to encode.\n","                    add_special_tokens = True,      # Add the special tokens.\n","                    max_length = MAX_LEN,\n","                    truncation=True,           # Pad & truncate all sentences.\n","                    pad_to_max_length = True,\n","                    return_attention_mask = True,   # Construct attn. masks.\n","                    return_tensors = 'pt',          # Return pytorch tensors.\n","               )\n","        \n","        # These are torch tensors.\n","        padded_token_list = encoded_dict['input_ids'][0]\n","        att_mask = encoded_dict['attention_mask'][0]\n","        \n","        # Convert the target to a torch tensor\n","        target = torch.tensor(self.df_data.loc[index, 'label'])\n","\n","        sample = (padded_token_list, att_mask, target)\n","\n","\n","        return sample\n","\n","\n","    def __len__(self):\n","        return len(self.df_data)\n","    \n","\n","class TestDataset(Dataset):\n","\n","    def __init__(self, df):\n","        self.df_data = df\n","\n","\n","\n","    def __getitem__(self, index):\n","\n","        # get the sentence from the dataframe\n","        sentence1 = self.df_data.loc[index, 'premise']\n","        sentence2 = self.df_data.loc[index, 'hypothesis']\n","\n","        # Process the sentence\n","        # ---------------------\n","\n","        encoded_dict = tokenizer.encode_plus(\n","                    sentence1, sentence2,           # Sentence to encode.\n","                    add_special_tokens = True,      # Add the special tokens.\n","                    max_length = MAX_LEN,           # Pad & truncate all sentences.\n","                    truncation=True,           # Pad & truncate all sentences.\n","                    pad_to_max_length = True,\n","                    return_attention_mask = True,   # Construct attn. masks.\n","                    return_tensors = 'pt',          # Return pytorch tensors.\n","               )\n","        \n","        # These are torch tensors.\n","        padded_token_list = encoded_dict['input_ids'][0]\n","        att_mask = encoded_dict['attention_mask'][0]\n","        \n","               \n","\n","        sample = (padded_token_list, att_mask)\n","\n","\n","        return sample\n","\n","\n","    def __len__(self):\n","        return len(self.df_data)"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12587,"status":"ok","timestamp":1671545902740,"user":{"displayName":"Dominik Bieri","userId":"16263014991290198195"},"user_tz":-60},"id":"ofiWSvAdtm26","outputId":"e2a9e962-137d-4fa6-83cd-e0e6a8b36a20"},"outputs":[{"output_type":"stream","name":"stderr","text":["You are using a model of type xlm-roberta to instantiate a model of type roberta. This is not supported for all configurations of models and can yield errors.\n","Some weights of the model checkpoint at joeddav/xlm-roberta-large-xnli were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"execute_result","data":{"text/plain":["RobertaForSequenceClassification(\n","  (roberta): RobertaModel(\n","    (embeddings): RobertaEmbeddings(\n","      (word_embeddings): Embedding(250002, 1024, padding_idx=1)\n","      (position_embeddings): Embedding(514, 1024, padding_idx=1)\n","      (token_type_embeddings): Embedding(1, 1024)\n","      (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): RobertaEncoder(\n","      (layer): ModuleList(\n","        (0): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (1): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (2): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (3): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (4): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (5): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (6): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (7): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (8): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (9): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (10): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (11): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (12): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (13): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (14): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (15): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (16): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (17): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (18): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (19): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (20): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (21): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (22): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (23): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","  )\n","  (classifier): RobertaClassificationHead(\n","    (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","    (dropout): Dropout(p=0.1, inplace=False)\n","    (out_proj): Linear(in_features=1024, out_features=3, bias=True)\n","  )\n",")"]},"metadata":{},"execution_count":14}],"source":["from transformers import RobertaForSequenceClassification\n","\n","model = RobertaForSequenceClassification.from_pretrained(\n","    MODEL_TYPE, \n","    num_labels = 3, # The number of output labels. 2 for binary classification.\n",")\n","\n","# Send the model to the device.\n","model.to(device)"]},{"cell_type":"code","execution_count":15,"metadata":{"executionInfo":{"elapsed":16,"status":"ok","timestamp":1671545902740,"user":{"displayName":"Dominik Bieri","userId":"16263014991290198195"},"user_tz":-60},"id":"gdtKOQrDtm28"},"outputs":[],"source":["# Define the optimizer\n","optimizer = AdamW(model.parameters(),\n","              lr = L_RATE, \n","              eps = 1e-8 \n","            )"]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12,"status":"ok","timestamp":1671545902741,"user":{"displayName":"Dominik Bieri","userId":"16263014991290198195"},"user_tz":-60},"id":"cLl5oQa5tm28","outputId":"b0829c1e-e868-4dc2-9b21-a2eaff99a7a6"},"outputs":[{"output_type":"stream","name":"stdout","text":["307\n","38\n","163\n"]}],"source":["# Create the dataloaders.\n","\n","train_data = CompDataset(df_mnli)\n","val_data = CompDataset(df_val)\n","test_data = TestDataset(df_test)\n","\n","train_dataloader = torch.utils.data.DataLoader(train_data,\n","                                        batch_size=BATCH_SIZE,\n","                                        shuffle=True,\n","                                       num_workers=NUM_CORES)\n","\n","val_dataloader = torch.utils.data.DataLoader(val_data,\n","                                        batch_size=BATCH_SIZE,\n","                                        shuffle=True,\n","                                       num_workers=NUM_CORES)\n","\n","test_dataloader = torch.utils.data.DataLoader(test_data,\n","                                        batch_size=BATCH_SIZE,\n","                                        shuffle=False,\n","                                       num_workers=NUM_CORES)\n","\n","\n","\n","print(len(train_dataloader))\n","print(len(val_dataloader))\n","print(len(test_dataloader))"]},{"cell_type":"code","execution_count":17,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1723316,"status":"ok","timestamp":1671547626047,"user":{"displayName":"Dominik Bieri","userId":"16263014991290198195"},"user_tz":-60},"id":"l4x7Ge8jtm28","outputId":"39f98e86-83b0-4ba9-c628-a05df9813c89"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","======== Epoch 1 / 5 ========\n","Training on ...\n","cuda:0\n","Train loss: 107.74848488718271\n","\n","Validation...\n","Val loss: 3.709232073277235\n","Val acc:  0.9678217821782178\n","\n","======== Epoch 2 / 5 ========\n","Training on ...\n","cuda:0\n","Train loss: 55.394875794649124\n","\n","Validation...\n","Val loss: 2.1274984730407596\n","Val acc:  0.9801980198019802\n","\n","======== Epoch 3 / 5 ========\n","Training on ...\n","cuda:0\n","Train loss: 31.020631619845517\n","\n","Validation...\n","Val loss: 2.3481050117406994\n","Val acc:  0.9843234323432343\n","\n","======== Epoch 4 / 5 ========\n","Training on ...\n","cuda:0\n","Train loss: 23.558650817663874\n","\n","Validation...\n","Val loss: 2.401188115880359\n","Val acc:  0.9876237623762376\n","\n","======== Epoch 5 / 5 ========\n","Training on ...\n","cuda:0\n","Train loss: 19.330399783531902\n","\n","Validation...\n","Val loss: 2.9874719649378676\n","Val acc:  0.985973597359736\n"]}],"source":["# Set the seed.\n","seed_val = 400\n","\n","random.seed(seed_val)\n","np.random.seed(seed_val)\n","torch.manual_seed(seed_val)\n","torch.cuda.manual_seed_all(seed_val)\n","\n","# Store the average loss after each epoch so we can plot them.\n","loss_values = []\n","\n","\n","# For each epoch...\n","for epoch in range(0, NUM_EPOCHS):\n","    \n","    print(\"\")\n","    print('======== Epoch {:} / {:} ========'.format(epoch + 1, NUM_EPOCHS))\n","    \n","\n","    stacked_val_labels = []\n","    targets_list = []\n","\n","\n","# ========================================\n","    #               Training\n","    # ========================================\n","    \n","    print('Training on ...')\n","    print(model.device)\n","    \n","    # put the model into train mode\n","    model.train()\n","    \n","    # This turns gradient calculations on and off.\n","    torch.set_grad_enabled(True)\n","\n","\n","    # Reset the total loss for this epoch.\n","    total_train_loss = 0\n","\n","    for i, batch in enumerate(train_dataloader):\n","        \n","        train_status = 'Batch ' + str(i) + ' of ' + str(len(train_dataloader))\n","        \n","        print(train_status, end='\\r')\n","\n","\n","        b_input_ids = batch[0].to(device)\n","        b_input_mask = batch[1].to(device)\n","        b_labels = batch[2].to(device)\n","\n","        model.zero_grad()\n","\n","        outputs = model(b_input_ids, \n","                    attention_mask=b_input_mask,\n","                    labels=b_labels)\n","        \n","        # Get the loss from the outputs tuple: (loss, logits)\n","        loss = outputs[0]\n","        \n","        # Convert the loss from a torch tensor to a number.\n","        # Calculate the total loss.\n","        total_train_loss = total_train_loss + loss.item()\n","        \n","        # Zero the gradients\n","        optimizer.zero_grad()\n","        \n","        # Perform a backward pass to calculate the gradients.\n","        loss.backward()\n","        \n","        \n","        # Clip the norm of the gradients to 1.0.\n","        # This is to help prevent the \"exploding gradients\" problem.\n","        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n","        \n","        \n","        \n","        # Use the optimizer to update the weights.\n","        \n","        # Optimizer for GPU\n","        optimizer.step() \n","        \n","\n","\n","    \n","    print('Train loss:' ,total_train_loss)\n","\n","\n","\n","    # ========================================\n","    #               Validation\n","    # ========================================\n","    \n","    print('\\nValidation...')\n","\n","    # Put the model in evaluation mode.\n","    model.eval()\n","\n","    # Turn off the gradient calculations.\n","    # This tells the model not to compute or store gradients.\n","    # This step saves memory and speeds up validation.\n","    torch.set_grad_enabled(False)\n","    \n","    \n","    # Reset the total loss for this epoch.\n","    total_val_loss = 0\n","    \n","\n","    for j, batch in enumerate(val_dataloader):\n","            \n","            val_status = 'Batch ' + str(j) + ' of ' + str(len(val_dataloader))\n","            \n","            print(val_status, end='\\r')\n","\n","            b_input_ids = batch[0].to(device)\n","            b_input_mask = batch[1].to(device)\n","            b_labels = batch[2].to(device)     \n","\n","\n","            outputs = model(b_input_ids, \n","                    attention_mask=b_input_mask, \n","                    labels=b_labels)\n","            \n","            # Get the loss from the outputs tuple: (loss, logits)\n","            loss = outputs[0]\n","            \n","            # Convert the loss from a torch tensor to a number.\n","            # Calculate the total loss.\n","            total_val_loss = total_val_loss + loss.item()\n","            \n","\n","            # Get the preds\n","            preds = outputs[1]\n","\n","\n","            # Move preds to the CPU\n","            val_preds = preds.detach().cpu().numpy()\n","            \n","            # Move the labels to the cpu\n","            targets_np = b_labels.to('cpu').numpy()\n","\n","            # Append the labels to a numpy list\n","            targets_list.extend(targets_np)\n","\n","            if j == 0:  # first batch\n","                stacked_val_preds = val_preds\n","            else:\n","                stacked_val_preds = np.vstack((stacked_val_preds, val_preds))\n","\n","        \n","        # Calculate the validation accuracy\n","    y_true = targets_list\n","    y_pred = np.argmax(stacked_val_preds, axis=1)\n","        \n","    val_acc = accuracy_score(y_true, y_pred)\n","        \n","        \n","    print('Val loss:' ,total_val_loss)\n","    print('Val acc: ', val_acc)\n","\n","\n","  # Use the garbage collector to save memory.\n","    gc.collect()\n","# Save the Model\n","torch.save(model.state_dict(), 'drive/MyDrive/NLP_Project/data/xlm_roberta_large_xnli_mlni_mnli_val_matched.pt')\n","\n","    "]},{"cell_type":"code","execution_count":18,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":55927,"status":"ok","timestamp":1671547681970,"user":{"displayName":"Dominik Bieri","userId":"16263014991290198195"},"user_tz":-60},"id":"Shqyt17zC-L4","outputId":"9d3eb9e9-bffb-4bfa-ac7c-0fe8eb317e53"},"outputs":[{"output_type":"stream","name":"stdout","text":[]}],"source":["for j, batch in enumerate(test_dataloader):\n","        \n","        inference_status = 'Batch ' + str(j+1) + ' of ' + str(len(test_dataloader))\n","        \n","        print(inference_status, end='\\r')\n","\n","        b_input_ids = batch[0].to(device)\n","        b_input_mask = batch[1].to(device)\n","\n","\n","        outputs = model(b_input_ids, \n","                attention_mask=b_input_mask)\n","        \n","        \n","        # Get the preds\n","        preds = outputs[0]\n","\n","\n","        # Move preds to the CPU\n","        preds = preds.detach().cpu().numpy()\n","        \n","        # Move the labels to the cpu\n","        targets_np = b_labels.to('cpu').numpy()\n","\n","        # Append the labels to a numpy list\n","        targets_list.extend(targets_np)\n","        \n","        # Stack the predictions.\n","\n","        if j == 0:  # first batch\n","            stacked_preds = preds\n","\n","        else:\n","            stacked_preds = np.vstack((stacked_preds, preds))"]},{"cell_type":"code","execution_count":19,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VlwPWZVRvgjX","executionInfo":{"status":"ok","timestamp":1671547681971,"user_tz":-60,"elapsed":10,"user":{"displayName":"Dominik Bieri","userId":"16263014991290198195"}},"outputId":"f51d71ac-64c8-48bf-ed76-20219f0f0c80"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([0, 1, 2, ..., 2, 2, 0])"]},"metadata":{},"execution_count":19}],"source":["# Take the argmax. This returns the column index of the max value in each row.\n","\n","preds = np.argmax(stacked_preds, axis=1)\n","\n","preds"]},{"cell_type":"code","execution_count":20,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":221},"executionInfo":{"elapsed":461,"status":"ok","timestamp":1671547682426,"user":{"displayName":"Dominik Bieri","userId":"16263014991290198195"},"user_tz":-60},"id":"TbQyrcZvvtGw","outputId":"c7289747-0dab-40b8-bc23-527fe9e233dd"},"outputs":[{"output_type":"stream","name":"stdout","text":["(5195, 2)\n"]},{"output_type":"execute_result","data":{"text/plain":["           id  prediction\n","0  c6d58c3f69           1\n","1  cefcc82292           1\n","2  e98005252c           1\n","3  58518c10ba           1\n","4  c32b0d16df           1"],"text/html":["\n","  <div id=\"df-7497e6ad-6a6f-499b-bacc-f3c87a38caa8\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>prediction</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>c6d58c3f69</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>cefcc82292</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>e98005252c</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>58518c10ba</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>c32b0d16df</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7497e6ad-6a6f-499b-bacc-f3c87a38caa8')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-7497e6ad-6a6f-499b-bacc-f3c87a38caa8 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-7497e6ad-6a6f-499b-bacc-f3c87a38caa8');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":20}],"source":["path = 'drive/MyDrive/NLP_Project/data/sample_submission.csv'\n","\n","df_sample = pd.read_csv(path)\n","\n","print(df_sample.shape)\n","\n","df_sample.head()"]},{"cell_type":"code","execution_count":21,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":204},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1671547682427,"user":{"displayName":"Dominik Bieri","userId":"16263014991290198195"},"user_tz":-60},"id":"4wCJ0FK4vwG1","outputId":"124a38ca-7f9b-4631-c84f-d86ac52e4ccd"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["           id  prediction\n","0  c6d58c3f69           2\n","1  cefcc82292           1\n","2  e98005252c           0\n","3  58518c10ba           1\n","4  c32b0d16df           1"],"text/html":["\n","  <div id=\"df-a3b41a4b-031a-4f24-a4f1-12a5a3a7bde1\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>prediction</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>c6d58c3f69</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>cefcc82292</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>e98005252c</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>58518c10ba</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>c32b0d16df</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a3b41a4b-031a-4f24-a4f1-12a5a3a7bde1')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-a3b41a4b-031a-4f24-a4f1-12a5a3a7bde1 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-a3b41a4b-031a-4f24-a4f1-12a5a3a7bde1');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":21}],"source":["df_sample['prediction'] = preds\n","df_sample['prediction'] = df_sample['prediction'].replace([0, 2], [2, 0])\n","\n","df_sample.head()"]},{"cell_type":"code","execution_count":22,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1671547682427,"user":{"displayName":"Dominik Bieri","userId":"16263014991290198195"},"user_tz":-60},"id":"M5WSPyiAvx9k"},"outputs":[],"source":["# Create a submission csv file\n","# Note that for this competition the submission file must be named submission.csv.\n","# Therefore, it won't be possible to submit this csv file for leaderboard scoring.\n","seed = 400\n","df_sample.to_csv(f'drive/MyDrive/NLP_Project/data/xlm roberta_large_mnli_submission_seed{seed}.csv', index=False)"]},{"cell_type":"code","execution_count":22,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1671547682428,"user":{"displayName":"Dominik Bieri","userId":"16263014991290198195"},"user_tz":-60},"id":"77Z42cOe6yCr"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[{"file_id":"18A3R5Sg7jVgwi2PBFOBdPSmPeDZzLZNM","timestamp":1670753116409}]},"gpuClass":"premium","kernelspec":{"display_name":"nlpproject","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.8 | packaged by conda-forge | (main, Nov 22 2022, 08:25:29) [Clang 14.0.6 ]"},"vscode":{"interpreter":{"hash":"1963e4c1efbc08bf37151025a3a70fa62b76f4594615bf06e73f232accade162"}},"widgets":{"application/vnd.jupyter.widget-state+json":{"3b1bacb8419c498d854d020c79847cc6":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c83fce16b6214a5bbc79385f03961e5d","IPY_MODEL_e9e4f6ab9e364a2d9a61b784ecf52806","IPY_MODEL_8b2b05f0e4a743e7b67fd6e817eb3a5f"],"layout":"IPY_MODEL_7fb4ad8c04c942ee81a4c462e29ba9f0"}},"c83fce16b6214a5bbc79385f03961e5d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_59db2e01f17f4736b16b2a4d61253d59","placeholder":"","style":"IPY_MODEL_c361381b324841e694dfcc68df691998","value":"100%"}},"e9e4f6ab9e364a2d9a61b784ecf52806":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_25f3146c716d4c939540347cbf5eb73e","max":5,"min":0,"orientation":"horizontal","style":"IPY_MODEL_1c09cfb3782c4d51a3a65e88f23c664f","value":5}},"8b2b05f0e4a743e7b67fd6e817eb3a5f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3d59e937083441c5b1f2592cd75ca9d4","placeholder":"","style":"IPY_MODEL_dffd536873e04a3b915f816b2a322d66","value":" 5/5 [00:00&lt;00:00, 207.79it/s]"}},"7fb4ad8c04c942ee81a4c462e29ba9f0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"59db2e01f17f4736b16b2a4d61253d59":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c361381b324841e694dfcc68df691998":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"25f3146c716d4c939540347cbf5eb73e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1c09cfb3782c4d51a3a65e88f23c664f":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"3d59e937083441c5b1f2592cd75ca9d4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dffd536873e04a3b915f816b2a322d66":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}