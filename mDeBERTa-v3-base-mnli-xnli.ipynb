{"cells":[{"cell_type":"markdown","id":"510b2743","metadata":{"id":"510b2743"},"source":["# mDeBERTa-v3-base-mnli-xnli"]},{"cell_type":"code","execution_count":null,"id":"30da7061","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"30da7061","outputId":"324390be-39c5-4513-a55b-65aefbc2f4ae","executionInfo":{"status":"ok","timestamp":1670921567875,"user_tz":-60,"elapsed":20104,"user":{"displayName":"masha wyss","userId":"07988247816707357061"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: sentencepiece in /usr/local/lib/python3.8/dist-packages (0.1.97)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: torch in /usr/local/lib/python3.8/dist-packages (1.13.0+cu116)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.8/dist-packages (0.14.0+cu116)\n","Requirement already satisfied: torchaudio in /usr/local/lib/python3.8/dist-packages (0.13.0+cu116)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch) (4.4.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from torchvision) (2.23.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from torchvision) (1.21.6)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.8/dist-packages (from torchvision) (7.1.2)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision) (2022.9.24)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (1.3.5)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas) (2.8.2)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas) (2022.6)\n","Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.8/dist-packages (from pandas) (1.21.6)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (1.21.6)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.8/dist-packages (1.0.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn) (3.1.0)\n","Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn) (1.7.3)\n","Requirement already satisfied: numpy>=1.14.6 in /usr/local/lib/python3.8/dist-packages (from scikit-learn) (1.21.6)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.8/dist-packages (from scikit-learn) (1.2.0)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: transformers in /usr/local/lib/python3.8/dist-packages (4.25.1)\n","Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2022.6.2)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (1.21.6)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.10.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (0.11.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.8.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers) (4.64.1)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (21.3)\n","Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (0.13.2)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.4.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2022.9.24)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2.10)\n","1.13.0+cu116\n"]}],"source":["!pip install sentencepiece\n","!pip3 install torch torchvision torchaudio\n","!pip install pandas\n","!pip install numpy\n","!pip install scikit-learn\n","!pip install transformers\n","\n","import pandas as pd\n","import numpy as np\n","import os\n","import gc\n","\n","import random\n","\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim \n","import torch.nn.functional as F\n","from torch.utils.data import Dataset, DataLoader\n","\n","# set a seed value\n","torch.manual_seed(555)\n","\n","from sklearn.utils import shuffle\n","from sklearn.metrics import roc_auc_score, accuracy_score\n","\n","import transformers\n","from transformers import BertTokenizer, BertForSequenceClassification \n","from transformers import XLMRobertaTokenizer, XLMRobertaForSequenceClassification\n","from transformers import AdamW\n","from transformers import AutoTokenizer, AutoModelForSequenceClassification\n","\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n","\n","\n","print(torch.__version__)"]},{"cell_type":"code","execution_count":null,"id":"b5b2330f","metadata":{"id":"b5b2330f","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1670921624915,"user_tz":-60,"elapsed":177,"user":{"displayName":"masha wyss","userId":"07988247816707357061"}},"outputId":"1b9c8ff4-aa42-48c0-a6cb-1e67818cf656"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["2"]},"metadata":{},"execution_count":42}],"source":["MODEL_TYPE = \"MoritzLaurer/mDeBERTa-v3-base-mnli-xnli\"\n","\n","\n","L_RATE = 2e-05\n","MAX_LEN = 256\n","\n","NUM_EPOCHS = 20\n","BATCH_SIZE = 32\n","NUM_CORES = os.cpu_count()\n","\n","NUM_CORES"]},{"cell_type":"code","execution_count":null,"id":"2f517be9","metadata":{"id":"2f517be9","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1670921627139,"user_tz":-60,"elapsed":506,"user":{"displayName":"masha wyss","userId":"07988247816707357061"}},"outputId":"6c859fdf-e555-4e95-e73e-7bb56a6b90f1"},"outputs":[{"output_type":"stream","name":"stdout","text":["Tue Dec 13 08:53:46 2022       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   51C    P0    26W /  70W |  15002MiB / 15109MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","+-----------------------------------------------------------------------------+\n"]}],"source":["gpu_info = !nvidia-smi\n","gpu_info = '\\n'.join(gpu_info)\n","if gpu_info.find('failed') >= 0:\n","    print('Not connected to a GPU')\n","else:\n","    print(gpu_info)"]},{"cell_type":"code","execution_count":null,"id":"f31132ba","metadata":{"id":"f31132ba","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1670921629801,"user_tz":-60,"elapsed":206,"user":{"displayName":"masha wyss","userId":"07988247816707357061"}},"outputId":"ad985c86-136a-48a7-8844-8ed005d9f1eb"},"outputs":[{"output_type":"stream","name":"stdout","text":["Your runtime has 13.6 gigabytes of available RAM\n","\n","Not using a high-RAM runtime\n"]}],"source":["from psutil import virtual_memory\n","ram_gb = virtual_memory().total / 1e9\n","print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n","\n","if ram_gb < 20:\n","    print('Not using a high-RAM runtime')\n","else:\n","    print('You are using a high-RAM runtime!')"]},{"cell_type":"code","execution_count":null,"id":"41d78fcb","metadata":{"id":"41d78fcb","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1670921631236,"user_tz":-60,"elapsed":4,"user":{"displayName":"masha wyss","userId":"07988247816707357061"}},"outputId":"e0d58547-97b6-42c1-a0e7-e9d52595ff34"},"outputs":[{"output_type":"stream","name":"stdout","text":["1\n"]}],"source":["print(torch.cuda.device_count())"]},{"cell_type":"code","execution_count":null,"id":"e253d96e","metadata":{"id":"e253d96e","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1670921633057,"user_tz":-60,"elapsed":773,"user":{"displayName":"masha wyss","userId":"07988247816707357061"}},"outputId":"2b95ac63-76fe-46cb-e67c-59221b7b7ad4"},"outputs":[{"output_type":"stream","name":"stdout","text":["Tesla T4\n"]}],"source":["print(torch.cuda.get_device_name(0))"]},{"cell_type":"code","execution_count":null,"id":"d11f6cd6","metadata":{"id":"d11f6cd6","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1670921633972,"user_tz":-60,"elapsed":5,"user":{"displayName":"masha wyss","userId":"07988247816707357061"}},"outputId":"5b2ef6f4-509b-4039-d933-4f35d75d2a6c"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["device(type='cuda', index=0)"]},"metadata":{},"execution_count":47}],"source":["device = torch.device('cuda:0')\n","device"]},{"cell_type":"code","execution_count":null,"id":"24eed09c","metadata":{"id":"24eed09c","outputId":"66bb86d0-3724-420f-9ab7-7c133db1e695","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1670921638319,"user_tz":-60,"elapsed":2248,"user":{"displayName":"masha wyss","userId":"07988247816707357061"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"id":"6646fd90","metadata":{"id":"6646fd90"},"outputs":[],"source":["df_train=pd.read_csv('/content/drive/MyDrive/Projekt/nlp_train.csv')\n","df_val=pd.read_csv('/content/drive/MyDrive/Projekt/test.csv')\n","df_test=pd.read_csv('/content/drive/MyDrive/Projekt/nlp_valid.csv')"]},{"cell_type":"code","execution_count":null,"id":"8977c502","metadata":{"id":"8977c502","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1670921654648,"user_tz":-60,"elapsed":4225,"user":{"displayName":"masha wyss","userId":"07988247816707357061"}},"outputId":"d70ce5f1-07c8-4eb7-eed0-4c91401b2b16"},"outputs":[{"output_type":"stream","name":"stdout","text":["Loading mDeBERTa-v3-base-mnli-xnli tokenizer...\n"]}],"source":["# impot \"MoritzLaurer/mDeBERTa-v3-base-mnli-xnli\"\n","print('Loading mDeBERTa-v3-base-mnli-xnli tokenizer...')\n","tokenizer = AutoTokenizer.from_pretrained(MODEL_TYPE)"]},{"cell_type":"code","source":["df_train = df_train.reset_index(drop=True)\n","df_val = df_val.reset_index(drop=True)"],"metadata":{"id":"vJKmBSzoqYmu"},"id":"vJKmBSzoqYmu","execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"id":"50dee767","metadata":{"id":"50dee767"},"outputs":[],"source":["class CompDataset(Dataset):\n","\n","    def __init__(self, df):\n","        self.df_data = df\n","\n","\n","\n","    def __getitem__(self, index):\n","\n","        # get the sentence from the dataframe\n","        sentence1 = self.df_data.loc[index, 'premise']\n","        sentence2 = self.df_data.loc[index, 'hypothesis']\n","\n","        # Process the sentence\n","        # ---------------------\n","\n","        encoded_dict = tokenizer.encode_plus(\n","                    sentence1, sentence2,           # Sentences to encode.\n","                    add_special_tokens = True,      # Add the special tokens.\n","                    max_length = MAX_LEN,\n","                    truncation=True,                 # Pad & truncate all sentences.\n","                    pad_to_max_length = True,\n","                    return_attention_mask = True,   # Construct attn. masks.\n","                    return_tensors = 'pt',          # Return pytorch tensors.\n","               )\n","        \n","        # These are torch tensors.\n","        padded_token_list = encoded_dict['input_ids'][0]\n","        att_mask = encoded_dict['attention_mask'][0]\n","        \n","        # Convert the target to a torch tensor\n","        target = torch.tensor(self.df_data.loc[index, 'label'])\n","\n","        sample = (padded_token_list, att_mask, target)\n","\n","\n","        return sample\n","\n","\n","    def __len__(self):\n","        return len(self.df_data)\n","    \n","\n","class TestDataset(Dataset):\n","\n","    def __init__(self, df):\n","        self.df_data = df\n","\n","\n","\n","    def __getitem__(self, index):\n","\n","        # get the sentence from the dataframe\n","        sentence1 = self.df_data.loc[index, 'premise']\n","        sentence2 = self.df_data.loc[index, 'hypothesis']\n","\n","        # Process the sentence\n","        # ---------------------\n","\n","        encoded_dict = tokenizer.encode_plus(\n","                    sentence1, sentence2,           # Sentence to encode.\n","                    add_special_tokens = True,      # Add the special tokens.\n","                    max_length = MAX_LEN,\n","                    truncation=True,           # Pad & truncate all sentences.\n","                    pad_to_max_length = True,\n","                    return_attention_mask = True,   # Construct attn. masks.\n","                    return_tensors = 'pt',          # Return pytorch tensors.\n","               )\n","        \n","        # These are torch tensors.\n","        padded_token_list = encoded_dict['input_ids'][0]\n","        att_mask = encoded_dict['attention_mask'][0]\n","        \n","               \n","\n","        sample = (padded_token_list, att_mask)\n","\n","\n","        return sample\n","\n","\n","    def __len__(self):\n","        return len(self.df_data)"]},{"cell_type":"code","execution_count":null,"id":"2a55bcb1","metadata":{"id":"2a55bcb1","colab":{"base_uri":"https://localhost:8080/","height":143},"executionInfo":{"status":"ok","timestamp":1670921436083,"user_tz":-60,"elapsed":665,"user":{"displayName":"masha wyss","userId":"07988247816707357061"}},"outputId":"1d5207fa-435c-479b-ed9d-2d52a4294b46"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["'\\ndf_train = df_train.reset_index(drop=True)\\ndf_val = df_val.reset_index(drop=True)\\ntrain_data = CompDataset(df_train)\\nval_data = CompDataset(df_val)\\ntest_data = TestDataset(df_test)\\n\\n\\ntrain_dataloader = torch.utils.data.DataLoader(train_data,\\n                                        batch_size=BATCH_SIZE,\\n                                        shuffle=True,\\n                                       num_workers=NUM_CORES)\\n\\nval_dataloader = torch.utils.data.DataLoader(val_data,\\n                                        batch_size=BATCH_SIZE,\\n                                        shuffle=True,\\n                                       num_workers=NUM_CORES)\\n\\ntest_dataloader = torch.utils.data.DataLoader(test_data,\\n                                        batch_size=BATCH_SIZE,\\n                                        shuffle=False,\\n                                       num_workers=NUM_CORES)\\n\\n\\nprint(len(train_dataloader))\\nprint(len(val_dataloader))\\nprint(len(test_dataloader))\\n'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":30}],"source":["\"\"\"\n","df_train = df_train.reset_index(drop=True)\n","df_val = df_val.reset_index(drop=True)\n","train_data = CompDataset(df_train)\n","val_data = CompDataset(df_val)\n","test_data = TestDataset(df_test)\n","\n","\n","train_dataloader = torch.utils.data.DataLoader(train_data,\n","                                        batch_size=BATCH_SIZE,\n","                                        shuffle=True,\n","                                       num_workers=NUM_CORES)\n","\n","val_dataloader = torch.utils.data.DataLoader(val_data,\n","                                        batch_size=BATCH_SIZE,\n","                                        shuffle=True,\n","                                       num_workers=NUM_CORES)\n","\n","test_dataloader = torch.utils.data.DataLoader(test_data,\n","                                        batch_size=BATCH_SIZE,\n","                                        shuffle=False,\n","                                       num_workers=NUM_CORES)\n","\n","\n","print(len(train_dataloader))\n","print(len(val_dataloader))\n","print(len(test_dataloader))\n","\"\"\""]},{"cell_type":"code","execution_count":null,"id":"f5431c4d","metadata":{"id":"f5431c4d"},"outputs":[],"source":["\"\"\"\n","# Get one train batch\n","\n","padded_token_list, att_mask, target = next(iter(train_dataloader))\n","\n","print(padded_token_list.shape)\n","print(att_mask.shape)\n","print(target.shape)\n","\n","# Get one val batch\n","\n","#padded_token_list, att_mask, target = next(iter(val_dataloader)) THROWS KEY ERROR - WHY?\n","\n","print(padded_token_list.shape)\n","print(att_mask.shape)\n","print(target.shape)\n","\n","# Get one test batch\n","\n","padded_token_list, att_mask = next(iter(test_dataloader))\n","\n","print(padded_token_list.shape)\n","print(att_mask.shape)\n","\"\"\"\""]},{"cell_type":"code","execution_count":null,"id":"96f4e8c4","metadata":{"id":"96f4e8c4","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1670921673828,"user_tz":-60,"elapsed":4541,"user":{"displayName":"masha wyss","userId":"07988247816707357061"}},"outputId":"3a256f25-e7cf-417a-f32e-e28a900f2655"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["DebertaV2ForSequenceClassification(\n","  (deberta): DebertaV2Model(\n","    (embeddings): DebertaV2Embeddings(\n","      (word_embeddings): Embedding(251000, 768, padding_idx=0)\n","      (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n","      (dropout): StableDropout()\n","    )\n","    (encoder): DebertaV2Encoder(\n","      (layer): ModuleList(\n","        (0): DebertaV2Layer(\n","          (attention): DebertaV2Attention(\n","            (self): DisentangledSelfAttention(\n","              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (pos_dropout): StableDropout()\n","              (dropout): StableDropout()\n","            )\n","            (output): DebertaV2SelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n","              (dropout): StableDropout()\n","            )\n","          )\n","          (intermediate): DebertaV2Intermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): DebertaV2Output(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n","            (dropout): StableDropout()\n","          )\n","        )\n","        (1): DebertaV2Layer(\n","          (attention): DebertaV2Attention(\n","            (self): DisentangledSelfAttention(\n","              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (pos_dropout): StableDropout()\n","              (dropout): StableDropout()\n","            )\n","            (output): DebertaV2SelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n","              (dropout): StableDropout()\n","            )\n","          )\n","          (intermediate): DebertaV2Intermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): DebertaV2Output(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n","            (dropout): StableDropout()\n","          )\n","        )\n","        (2): DebertaV2Layer(\n","          (attention): DebertaV2Attention(\n","            (self): DisentangledSelfAttention(\n","              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (pos_dropout): StableDropout()\n","              (dropout): StableDropout()\n","            )\n","            (output): DebertaV2SelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n","              (dropout): StableDropout()\n","            )\n","          )\n","          (intermediate): DebertaV2Intermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): DebertaV2Output(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n","            (dropout): StableDropout()\n","          )\n","        )\n","        (3): DebertaV2Layer(\n","          (attention): DebertaV2Attention(\n","            (self): DisentangledSelfAttention(\n","              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (pos_dropout): StableDropout()\n","              (dropout): StableDropout()\n","            )\n","            (output): DebertaV2SelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n","              (dropout): StableDropout()\n","            )\n","          )\n","          (intermediate): DebertaV2Intermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): DebertaV2Output(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n","            (dropout): StableDropout()\n","          )\n","        )\n","        (4): DebertaV2Layer(\n","          (attention): DebertaV2Attention(\n","            (self): DisentangledSelfAttention(\n","              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (pos_dropout): StableDropout()\n","              (dropout): StableDropout()\n","            )\n","            (output): DebertaV2SelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n","              (dropout): StableDropout()\n","            )\n","          )\n","          (intermediate): DebertaV2Intermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): DebertaV2Output(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n","            (dropout): StableDropout()\n","          )\n","        )\n","        (5): DebertaV2Layer(\n","          (attention): DebertaV2Attention(\n","            (self): DisentangledSelfAttention(\n","              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (pos_dropout): StableDropout()\n","              (dropout): StableDropout()\n","            )\n","            (output): DebertaV2SelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n","              (dropout): StableDropout()\n","            )\n","          )\n","          (intermediate): DebertaV2Intermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): DebertaV2Output(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n","            (dropout): StableDropout()\n","          )\n","        )\n","        (6): DebertaV2Layer(\n","          (attention): DebertaV2Attention(\n","            (self): DisentangledSelfAttention(\n","              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (pos_dropout): StableDropout()\n","              (dropout): StableDropout()\n","            )\n","            (output): DebertaV2SelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n","              (dropout): StableDropout()\n","            )\n","          )\n","          (intermediate): DebertaV2Intermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): DebertaV2Output(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n","            (dropout): StableDropout()\n","          )\n","        )\n","        (7): DebertaV2Layer(\n","          (attention): DebertaV2Attention(\n","            (self): DisentangledSelfAttention(\n","              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (pos_dropout): StableDropout()\n","              (dropout): StableDropout()\n","            )\n","            (output): DebertaV2SelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n","              (dropout): StableDropout()\n","            )\n","          )\n","          (intermediate): DebertaV2Intermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): DebertaV2Output(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n","            (dropout): StableDropout()\n","          )\n","        )\n","        (8): DebertaV2Layer(\n","          (attention): DebertaV2Attention(\n","            (self): DisentangledSelfAttention(\n","              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (pos_dropout): StableDropout()\n","              (dropout): StableDropout()\n","            )\n","            (output): DebertaV2SelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n","              (dropout): StableDropout()\n","            )\n","          )\n","          (intermediate): DebertaV2Intermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): DebertaV2Output(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n","            (dropout): StableDropout()\n","          )\n","        )\n","        (9): DebertaV2Layer(\n","          (attention): DebertaV2Attention(\n","            (self): DisentangledSelfAttention(\n","              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (pos_dropout): StableDropout()\n","              (dropout): StableDropout()\n","            )\n","            (output): DebertaV2SelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n","              (dropout): StableDropout()\n","            )\n","          )\n","          (intermediate): DebertaV2Intermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): DebertaV2Output(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n","            (dropout): StableDropout()\n","          )\n","        )\n","        (10): DebertaV2Layer(\n","          (attention): DebertaV2Attention(\n","            (self): DisentangledSelfAttention(\n","              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (pos_dropout): StableDropout()\n","              (dropout): StableDropout()\n","            )\n","            (output): DebertaV2SelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n","              (dropout): StableDropout()\n","            )\n","          )\n","          (intermediate): DebertaV2Intermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): DebertaV2Output(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n","            (dropout): StableDropout()\n","          )\n","        )\n","        (11): DebertaV2Layer(\n","          (attention): DebertaV2Attention(\n","            (self): DisentangledSelfAttention(\n","              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (pos_dropout): StableDropout()\n","              (dropout): StableDropout()\n","            )\n","            (output): DebertaV2SelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n","              (dropout): StableDropout()\n","            )\n","          )\n","          (intermediate): DebertaV2Intermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): DebertaV2Output(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n","            (dropout): StableDropout()\n","          )\n","        )\n","      )\n","      (rel_embeddings): Embedding(512, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n","    )\n","  )\n","  (pooler): ContextPooler(\n","    (dense): Linear(in_features=768, out_features=768, bias=True)\n","    (dropout): StableDropout()\n","  )\n","  (classifier): Linear(in_features=768, out_features=3, bias=True)\n","  (dropout): StableDropout()\n",")"]},"metadata":{},"execution_count":54}],"source":["\n","model = AutoModelForSequenceClassification.from_pretrained(\n","    MODEL_TYPE, \n","    num_labels = 3, # The number of output labels. 2 for binary classification.\n",")\n","\n","# Send the model to the device.\n","model.to(device)"]},{"cell_type":"code","execution_count":null,"id":"76092d4a","metadata":{"id":"76092d4a","colab":{"base_uri":"https://localhost:8080/","height":89},"executionInfo":{"status":"ok","timestamp":1670921697556,"user_tz":-60,"elapsed":190,"user":{"displayName":"masha wyss","userId":"07988247816707357061"}},"outputId":"ea75cd05-d63c-4b59-e6a0-77f9cc671e92"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["\"\\n# Create a batch of train samples\\n# We will set a small batch size of 8 so that the model's output can be easily displayed.\\n\\ntrain_dataloader = torch.utils.data.DataLoader(train_data,\\n                                        batch_size=8,\\n                                        shuffle=True,\\n                                       num_workers=NUM_CORES)\\n\\nb_input_ids, b_input_mask, b_labels = next(iter(train_dataloader))\\n\\nprint(b_input_ids.shape)\\nprint(b_input_mask.shape)\\nprint(b_labels.shape)\\n\""],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":55}],"source":["\"\"\"\n","# Create a batch of train samples\n","# We will set a small batch size of 8 so that the model's output can be easily displayed.\n","\n","train_dataloader = torch.utils.data.DataLoader(train_data,\n","                                        batch_size=8,\n","                                        shuffle=True,\n","                                       num_workers=NUM_CORES)\n","\n","b_input_ids, b_input_mask, b_labels = next(iter(train_dataloader))\n","\n","print(b_input_ids.shape)\n","print(b_input_mask.shape)\n","print(b_labels.shape)\n","\"\"\"\n"]},{"cell_type":"code","execution_count":null,"id":"dea9e3ec","metadata":{"id":"dea9e3ec","colab":{"base_uri":"https://localhost:8080/","height":151},"executionInfo":{"status":"error","timestamp":1670921708608,"user_tz":-60,"elapsed":514,"user":{"displayName":"masha wyss","userId":"07988247816707357061"}},"outputId":"d1780d1c-c07b-4f67-b5e5-89ce4a26f08a"},"outputs":[{"output_type":"error","ename":"SyntaxError","evalue":"ignored","traceback":["\u001b[0;36m  File \u001b[0;32m\"<ipython-input-56-ade87fe4d25c>\"\u001b[0;36m, line \u001b[0;32m18\u001b[0m\n\u001b[0;31m    \"\"\"\"\u001b[0m\n\u001b[0m        \n^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m EOL while scanning string literal\n"]}],"source":["\"\"\"\n","# Pass a batch of train samples to the model.\n","\n","batch = next(iter(train_dataloader))\n","\n","# Send the data to the device\n","b_input_ids = batch[0].to(device)\n","b_input_mask = batch[1].to(device)\n","b_labels = batch[2].to(device)\n","\n","# Run the model\n","outputs = model(b_input_ids, \n","                        attention_mask=b_input_mask, \n","                        labels=b_labels)\n","\n","# The ouput is a tuple (loss, preds).\n","outputs\n","\"\"\""]},{"cell_type":"code","execution_count":null,"id":"0112b1a3","metadata":{"id":"0112b1a3","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1670921720307,"user_tz":-60,"elapsed":305,"user":{"displayName":"masha wyss","userId":"07988247816707357061"}},"outputId":"ea034ab0-6325-449b-ddd0-11db2de93961"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["'\\npreds = outputs[1].detach().cpu().numpy()\\n\\ny_true = b_labels.detach().cpu().numpy()\\ny_pred = np.argmax(preds, axis=1)\\n\\ny_pred\\n'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":57}],"source":["\"\"\"\n","preds = outputs[1].detach().cpu().numpy()\n","\n","y_true = b_labels.detach().cpu().numpy()\n","y_pred = np.argmax(preds, axis=1)\n","\n","y_pred\n","\"\"\""]},{"cell_type":"code","execution_count":null,"id":"f4046a11","metadata":{"id":"f4046a11","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1670921734874,"user_tz":-60,"elapsed":204,"user":{"displayName":"masha wyss","userId":"07988247816707357061"}},"outputId":"9d862bfe-4ba4-46e6-e7d5-2fe2f09d0a22"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["'\\n# This is the accuracy without fine tuning.\\n\\nval_acc = accuracy_score(y_true, y_pred)\\n\\nval_acc\\n'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":58}],"source":["\"\"\"\n","# This is the accuracy without fine tuning.\n","\n","val_acc = accuracy_score(y_true, y_pred)\n","\n","val_acc\n","\"\"\""]},{"cell_type":"code","execution_count":null,"id":"90b53282","metadata":{"id":"90b53282","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1670921737431,"user_tz":-60,"elapsed":9,"user":{"displayName":"masha wyss","userId":"07988247816707357061"}},"outputId":"56e245c2-8aa7-4d05-ab34-5fd812c90e42"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["'\\n# The loss and preds are Torch tensors\\n\\nprint(type(outputs[0]))\\nprint(type(outputs[1]))\\n'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":59}],"source":["\"\"\"\n","# The loss and preds are Torch tensors\n","\n","print(type(outputs[0]))\n","print(type(outputs[1]))\n","\"\"\""]},{"cell_type":"code","execution_count":null,"id":"4c437108","metadata":{"id":"4c437108"},"outputs":[],"source":["# Define the optimizer\n","optimizer = AdamW(model.parameters(),\n","              lr = L_RATE, \n","              eps = 1e-8 \n","            )\n"]},{"cell_type":"code","execution_count":null,"id":"a88be354","metadata":{"id":"a88be354","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1670921759107,"user_tz":-60,"elapsed":189,"user":{"displayName":"masha wyss","userId":"07988247816707357061"}},"outputId":"51bdecff-a955-420a-9f13-80d9ac7a8b4b"},"outputs":[{"output_type":"stream","name":"stdout","text":["341\n","163\n","38\n"]}],"source":["# Create the dataloaders.\n","\n","train_data = CompDataset(df_train)\n","val_data = CompDataset(df_val)\n","test_data = TestDataset(df_test)\n","\n","train_dataloader = torch.utils.data.DataLoader(train_data,\n","                                        batch_size=BATCH_SIZE,\n","                                        shuffle=True,\n","                                       num_workers=NUM_CORES)\n","\n","val_dataloader = torch.utils.data.DataLoader(val_data,\n","                                        batch_size=BATCH_SIZE,\n","                                        shuffle=True,\n","                                       num_workers=NUM_CORES)\n","\n","test_dataloader = torch.utils.data.DataLoader(test_data,\n","                                        batch_size=BATCH_SIZE,\n","                                        shuffle=False,\n","                                       num_workers=NUM_CORES)\n","\n","\n","\n","print(len(train_dataloader))\n","print(len(val_dataloader))\n","print(len(test_dataloader))"]},{"cell_type":"code","source":["import torch\n","torch.cuda.empty_cache()"],"metadata":{"id":"u1qREXbWXvX3"},"id":"u1qREXbWXvX3","execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"id":"441e4c54","metadata":{"id":"441e4c54","colab":{"base_uri":"https://localhost:8080/","height":550},"executionInfo":{"status":"ok","timestamp":1670921852337,"user_tz":-60,"elapsed":1179,"user":{"displayName":"masha wyss","userId":"07988247816707357061"}},"outputId":"9e7c9c6e-6c1b-4ba0-b993-64ae3fc7f46e"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","======== Epoch 1 / 20 ========\n","Training on ...\n","cuda:0\n"]},{"output_type":"error","ename":"OutOfMemoryError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)","\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1188\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1191\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/models/deberta_v2/modeling_deberta_v2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1341\u001b[0m         \u001b[0mreturn_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_return_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1342\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1343\u001b[0;31m         outputs = self.deberta(\n\u001b[0m\u001b[1;32m   1344\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1345\u001b[0m             \u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1188\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1191\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/models/deberta_v2/modeling_deberta_v2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, inputs_embeds, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1107\u001b[0m         )\n\u001b[1;32m   1108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1109\u001b[0;31m         encoder_outputs = self.encoder(\n\u001b[0m\u001b[1;32m   1110\u001b[0m             \u001b[0membedding_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1111\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1188\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1191\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/models/deberta_v2/modeling_deberta_v2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, output_hidden_states, output_attentions, query_states, relative_pos, return_dict)\u001b[0m\n\u001b[1;32m    544\u001b[0m                 )\n\u001b[1;32m    545\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 546\u001b[0;31m                 output_states = layer_module(\n\u001b[0m\u001b[1;32m    547\u001b[0m                     \u001b[0mnext_kv\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m                     \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1188\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1191\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/models/deberta_v2/modeling_deberta_v2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, query_states, relative_pos, rel_embeddings, output_attentions)\u001b[0m\n\u001b[1;32m    384\u001b[0m         \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m     ):\n\u001b[0;32m--> 386\u001b[0;31m         attention_output = self.attention(\n\u001b[0m\u001b[1;32m    387\u001b[0m             \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    388\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1188\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1191\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/models/deberta_v2/modeling_deberta_v2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, output_attentions, query_states, relative_pos, rel_embeddings)\u001b[0m\n\u001b[1;32m    315\u001b[0m         \u001b[0mrel_embeddings\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m     ):\n\u001b[0;32m--> 317\u001b[0;31m         self_output = self.self(\n\u001b[0m\u001b[1;32m    318\u001b[0m             \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1188\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1191\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/models/deberta_v2/modeling_deberta_v2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, output_attentions, query_states, relative_pos, rel_embeddings)\u001b[0m\n\u001b[1;32m    748\u001b[0m             \u001b[0mscale_factor\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    749\u001b[0m         \u001b[0mscale\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mscale_factor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 750\u001b[0;31m         \u001b[0mattention_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery_layer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mscale\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mquery_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    751\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelative_attention\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    752\u001b[0m             \u001b[0mrel_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos_dropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrel_embeddings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 96.00 MiB (GPU 0; 14.76 GiB total capacity; 13.70 GiB already allocated; 19.75 MiB free; 13.76 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"]}],"source":["\n","%%time\n","\n","\n","# Set the seed.\n","seed_val = 101\n","\n","random.seed(seed_val)\n","np.random.seed(seed_val)\n","torch.manual_seed(seed_val)\n","torch.cuda.manual_seed_all(seed_val)\n","\n","# Store the average loss after each epoch so we can plot them.\n","loss_values = []\n","\n","\n","# For each epoch...\n","for epoch in range(0, NUM_EPOCHS):\n","    \n","    print(\"\")\n","    print('======== Epoch {:} / {:} ========'.format(epoch + 1, NUM_EPOCHS))\n","    \n","\n","    stacked_val_labels = []\n","    targets_list = []\n","\n","\n","# ========================================\n","    #               Training\n","    # ========================================\n","    \n","    print('Training on ...')\n","    print(model.device)\n","    \n","    # put the model into train mode\n","    model.train()\n","    \n","    # This turns gradient calculations on and off.\n","    torch.set_grad_enabled(True)\n","\n","\n","    # Reset the total loss for this epoch.\n","    total_train_loss = 0\n","\n","    for i, batch in enumerate(train_dataloader):\n","        \n","        train_status = 'Batch ' + str(i) + ' of ' + str(len(train_dataloader))\n","        \n","        print(train_status, end='\\r')\n","\n","\n","        b_input_ids = batch[0].to(device)\n","        b_input_mask = batch[1].to(device)\n","        b_labels = batch[2].to(device)\n","\n","        model.zero_grad()\n","\n","\n","        outputs = model(b_input_ids, \n","                    attention_mask=b_input_mask,\n","                    labels=b_labels)\n","        \n","        # Get the loss from the outputs tuple: (loss, logits)\n","        loss = outputs[0]\n","        \n","        # Convert the loss from a torch tensor to a number.\n","        # Calculate the total loss.\n","        total_train_loss = total_train_loss + loss.item()\n","        \n","        # Zero the gradients\n","        optimizer.zero_grad()\n","        \n","        # Perform a backward pass to calculate the gradients.\n","        loss.backward()\n","        \n","        \n","        # Clip the norm of the gradients to 1.0.\n","        # This is to help prevent the \"exploding gradients\" problem.\n","        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n","        \n","        \n","        \n","        # Use the optimizer to update the weights.\n","        \n","        # Optimizer for GPU\n","        optimizer.step() \n","        \n","        # Optimizer for TPU\n","        # https://pytorch.org/xla/\n","        #xm.optimizer_step(optimizer, barrier=True)\n","\n","    \n","    print('Train loss:' ,total_train_loss)\n","\n","\n","\n","    # ========================================\n","    #               Validation\n","    # ========================================\n","    \n","    print('\\nValidation...')\n","\n","    # Put the model in evaluation mode.\n","    model.eval()\n","\n","    # Turn off the gradient calculations.\n","    # This tells the model not to compute or store gradients.\n","    # This step saves memory and speeds up validation.\n","    torch.set_grad_enabled(False)\n","    \n","    \n","    # Reset the total loss for this epoch.\n","    total_val_loss = 0\n","    \n","\n","    for j, batch in enumerate(val_dataloader):\n","        \n","        val_status = 'Batch ' + str(j) + ' of ' + str(len(val_dataloader))\n","        \n","        print(val_status, end='\\r')\n","\n","        b_input_ids = batch[0].to(device)\n","        b_input_mask = batch[1].to(device)\n","        b_labels = batch[2].to(device)     \n","\n","\n","        outputs = model(b_input_ids, \n","                attention_mask=b_input_mask, \n","                labels=b_labels)\n","        \n","        # Get the loss from the outputs tuple: (loss, logits)\n","        loss = outputs[0]\n","        \n","        # Convert the loss from a torch tensor to a number.\n","        # Calculate the total loss.\n","        total_val_loss = total_val_loss + loss.item()\n","      \n","\n","\n","\n","        # Get the preds\n","        preds = outputs[1]\n","\n","\n","        # Move preds to the CPU\n","        val_preds = preds.detach().cpu().numpy()\n","        \n","        # Move the labels to the cpu\n","        targets_np = b_labels.to('cpu').numpy()\n","\n","        # Append the labels to a numpy list\n","        targets_list.extend(targets_np)\n","\n","        if j == 0:  # first batch\n","            stacked_val_preds = val_preds\n","        else:\n","            stacked_val_preds = np.vstack((stacked_val_preds, val_preds))\n","\n","    \n","    # Calculate the validation accuracy\n","    y_true = targets_list\n","    y_pred = np.argmax(stacked_val_preds, axis=1)\n","    \n","    val_acc = accuracy_score(y_true, y_pred)\n","    \n","    \n","    print('Val loss:' ,total_val_loss)\n","    print('Val acc: ', val_acc)\n","\n","\n","    # Save the Model\n","    torch.save(model.state_dict(), 'model.pt')\n","    \n","    # Use the garbage collector to save memory.\n","    gc.collect()\n"]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.2"},"colab":{"provenance":[]},"accelerator":"GPU","gpuClass":"standard"},"nbformat":4,"nbformat_minor":5}