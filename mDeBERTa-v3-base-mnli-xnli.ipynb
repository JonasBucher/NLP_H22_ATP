{"cells":[{"cell_type":"markdown","id":"510b2743","metadata":{"id":"510b2743"},"source":["# mDeBERTa-v3-base-mnli-xnli"]},{"cell_type":"code","execution_count":null,"id":"30da7061","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":20104,"status":"ok","timestamp":1670921567875,"user":{"displayName":"masha wyss","userId":"07988247816707357061"},"user_tz":-60},"id":"30da7061","outputId":"324390be-39c5-4513-a55b-65aefbc2f4ae"},"outputs":[],"source":["!pip install sentencepiece\n","!pip3 install torch torchvision torchaudio\n","!pip install pandas\n","!pip install numpy\n","!pip install scikit-learn\n","!pip install transformers\n","\n","import pandas as pd\n","import numpy as np\n","import os\n","import gc\n","\n","import random\n","\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim \n","import torch.nn.functional as F\n","from torch.utils.data import Dataset, DataLoader\n","\n","# set a seed value\n","torch.manual_seed(555)\n","\n","from sklearn.utils import shuffle\n","from sklearn.metrics import roc_auc_score, accuracy_score\n","\n","import transformers\n","from transformers import AdamW\n","from transformers import AutoTokenizer, AutoModelForSequenceClassification\n","\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n","\n","\n","print(torch.__version__)"]},{"cell_type":"code","execution_count":null,"id":"b5b2330f","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":177,"status":"ok","timestamp":1670921624915,"user":{"displayName":"masha wyss","userId":"07988247816707357061"},"user_tz":-60},"id":"b5b2330f","outputId":"1b9c8ff4-aa42-48c0-a6cb-1e67818cf656"},"outputs":[],"source":["MODEL_TYPE = \"MoritzLaurer/mDeBERTa-v3-base-mnli-xnli\"\n","\n","\n","L_RATE = 2e-05\n","MAX_LEN = 256\n","\n","NUM_EPOCHS = 20\n","BATCH_SIZE = 32\n","NUM_CORES = os.cpu_count()\n","\n","NUM_CORES"]},{"cell_type":"code","execution_count":null,"id":"d11f6cd6","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1670921633972,"user":{"displayName":"masha wyss","userId":"07988247816707357061"},"user_tz":-60},"id":"d11f6cd6","outputId":"5b2ef6f4-509b-4039-d933-4f35d75d2a6c"},"outputs":[],"source":["device = torch.device('cuda:0')\n","device"]},{"cell_type":"code","execution_count":null,"id":"24eed09c","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2248,"status":"ok","timestamp":1670921638319,"user":{"displayName":"masha wyss","userId":"07988247816707357061"},"user_tz":-60},"id":"24eed09c","outputId":"66bb86d0-3724-420f-9ab7-7c133db1e695"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"id":"6646fd90","metadata":{"id":"6646fd90"},"outputs":[],"source":["df_train=pd.read_csv('/content/drive/MyDrive/Projekt/nlp_train.csv')\n","df_val=pd.read_csv('/content/drive/MyDrive/Projekt/test.csv')\n","df_test=pd.read_csv('/content/drive/MyDrive/Projekt/nlp_valid.csv')"]},{"cell_type":"code","execution_count":null,"id":"8977c502","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4225,"status":"ok","timestamp":1670921654648,"user":{"displayName":"masha wyss","userId":"07988247816707357061"},"user_tz":-60},"id":"8977c502","outputId":"d70ce5f1-07c8-4eb7-eed0-4c91401b2b16"},"outputs":[],"source":["# impot \"MoritzLaurer/mDeBERTa-v3-base-mnli-xnli\"\n","print('Loading mDeBERTa-v3-base-mnli-xnli tokenizer...')\n","tokenizer = AutoTokenizer.from_pretrained(MODEL_TYPE)"]},{"cell_type":"code","execution_count":null,"id":"vJKmBSzoqYmu","metadata":{"id":"vJKmBSzoqYmu"},"outputs":[],"source":["df_train = df_train.reset_index(drop=True)\n","df_val = df_val.reset_index(drop=True)"]},{"cell_type":"code","execution_count":null,"id":"50dee767","metadata":{"id":"50dee767"},"outputs":[],"source":["class CompDataset(Dataset):\n","\n","    def __init__(self, df):\n","        self.df_data = df\n","\n","\n","\n","    def __getitem__(self, index):\n","\n","        # get the sentence from the dataframe\n","        sentence1 = self.df_data.loc[index, 'premise']\n","        sentence2 = self.df_data.loc[index, 'hypothesis']\n","\n","        # Process the sentence\n","        # ---------------------\n","\n","        encoded_dict = tokenizer.encode_plus(\n","                    sentence1, sentence2,           # Sentences to encode.\n","                    add_special_tokens = True,      # Add the special tokens.\n","                    max_length = MAX_LEN,\n","                    truncation=True,                 # Pad & truncate all sentences.\n","                    pad_to_max_length = True,\n","                    return_attention_mask = True,   # Construct attn. masks.\n","                    return_tensors = 'pt',          # Return pytorch tensors.\n","               )\n","        \n","        # These are torch tensors.\n","        padded_token_list = encoded_dict['input_ids'][0]\n","        att_mask = encoded_dict['attention_mask'][0]\n","        \n","        # Convert the target to a torch tensor\n","        target = torch.tensor(self.df_data.loc[index, 'label'])\n","\n","        sample = (padded_token_list, att_mask, target)\n","\n","\n","        return sample\n","\n","\n","    def __len__(self):\n","        return len(self.df_data)\n","    \n","\n","class TestDataset(Dataset):\n","\n","    def __init__(self, df):\n","        self.df_data = df\n","\n","\n","\n","    def __getitem__(self, index):\n","\n","        # get the sentence from the dataframe\n","        sentence1 = self.df_data.loc[index, 'premise']\n","        sentence2 = self.df_data.loc[index, 'hypothesis']\n","\n","        # Process the sentence\n","        # ---------------------\n","\n","        encoded_dict = tokenizer.encode_plus(\n","                    sentence1, sentence2,           # Sentence to encode.\n","                    add_special_tokens = True,      # Add the special tokens.\n","                    max_length = MAX_LEN,\n","                    truncation=True,           # Pad & truncate all sentences.\n","                    pad_to_max_length = True,\n","                    return_attention_mask = True,   # Construct attn. masks.\n","                    return_tensors = 'pt',          # Return pytorch tensors.\n","               )\n","        \n","        # These are torch tensors.\n","        padded_token_list = encoded_dict['input_ids'][0]\n","        att_mask = encoded_dict['attention_mask'][0]\n","        \n","               \n","\n","        sample = (padded_token_list, att_mask)\n","\n","\n","        return sample\n","\n","\n","    def __len__(self):\n","        return len(self.df_data)"]},{"cell_type":"code","execution_count":null,"id":"96f4e8c4","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4541,"status":"ok","timestamp":1670921673828,"user":{"displayName":"masha wyss","userId":"07988247816707357061"},"user_tz":-60},"id":"96f4e8c4","outputId":"3a256f25-e7cf-417a-f32e-e28a900f2655"},"outputs":[],"source":["\n","model = AutoModelForSequenceClassification.from_pretrained(\n","    MODEL_TYPE, \n","    num_labels = 3, # The number of output labels. 2 for binary classification.\n",")\n","\n","# Send the model to the device.\n","model.to(device)"]},{"cell_type":"code","execution_count":null,"id":"4c437108","metadata":{"id":"4c437108"},"outputs":[],"source":["# Define the optimizer\n","optimizer = AdamW(model.parameters(),\n","              lr = L_RATE, \n","              eps = 1e-8 \n","            )\n"]},{"cell_type":"code","execution_count":null,"id":"a88be354","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":189,"status":"ok","timestamp":1670921759107,"user":{"displayName":"masha wyss","userId":"07988247816707357061"},"user_tz":-60},"id":"a88be354","outputId":"51bdecff-a955-420a-9f13-80d9ac7a8b4b"},"outputs":[],"source":["# Create the dataloaders.\n","\n","train_data = CompDataset(df_train)\n","val_data = CompDataset(df_val)\n","test_data = TestDataset(df_test)\n","\n","train_dataloader = torch.utils.data.DataLoader(train_data,\n","                                        batch_size=BATCH_SIZE,\n","                                        shuffle=True,\n","                                       num_workers=NUM_CORES)\n","\n","val_dataloader = torch.utils.data.DataLoader(val_data,\n","                                        batch_size=BATCH_SIZE,\n","                                        shuffle=True,\n","                                       num_workers=NUM_CORES)\n","\n","test_dataloader = torch.utils.data.DataLoader(test_data,\n","                                        batch_size=BATCH_SIZE,\n","                                        shuffle=False,\n","                                       num_workers=NUM_CORES)\n","\n","\n","\n","print(len(train_dataloader))\n","print(len(val_dataloader))\n","print(len(test_dataloader))"]},{"cell_type":"code","execution_count":null,"id":"441e4c54","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":550},"executionInfo":{"elapsed":1179,"status":"ok","timestamp":1670921852337,"user":{"displayName":"masha wyss","userId":"07988247816707357061"},"user_tz":-60},"id":"441e4c54","outputId":"9e7c9c6e-6c1b-4ba0-b993-64ae3fc7f46e"},"outputs":[],"source":["# Set the seed.\n","seed_val = 101\n","\n","random.seed(seed_val)\n","np.random.seed(seed_val)\n","torch.manual_seed(seed_val)\n","torch.cuda.manual_seed_all(seed_val)\n","\n","# Store the average loss after each epoch so we can plot them.\n","loss_values = []\n","\n","\n","# For each epoch...\n","for epoch in range(0, NUM_EPOCHS):\n","    \n","    print(\"\")\n","    print('======== Epoch {:} / {:} ========'.format(epoch + 1, NUM_EPOCHS))\n","    \n","\n","    stacked_val_labels = []\n","    targets_list = []\n","\n","\n","# ========================================\n","    #               Training\n","    # ========================================\n","    \n","    print('Training on ...')\n","    print(model.device)\n","    \n","    # put the model into train mode\n","    model.train()\n","    \n","    # This turns gradient calculations on and off.\n","    torch.set_grad_enabled(True)\n","\n","\n","    # Reset the total loss for this epoch.\n","    total_train_loss = 0\n","\n","    for i, batch in enumerate(train_dataloader):\n","        \n","        train_status = 'Batch ' + str(i) + ' of ' + str(len(train_dataloader))\n","        \n","        print(train_status, end='\\r')\n","\n","\n","        b_input_ids = batch[0].to(device)\n","        b_input_mask = batch[1].to(device)\n","        b_labels = batch[2].to(device)\n","\n","        model.zero_grad()\n","\n","\n","        outputs = model(b_input_ids, \n","                    attention_mask=b_input_mask,\n","                    labels=b_labels)\n","        \n","        # Get the loss from the outputs tuple: (loss, logits)\n","        loss = outputs[0]\n","        \n","        # Convert the loss from a torch tensor to a number.\n","        # Calculate the total loss.\n","        total_train_loss = total_train_loss + loss.item()\n","        \n","        # Zero the gradients\n","        optimizer.zero_grad()\n","        \n","        # Perform a backward pass to calculate the gradients.\n","        loss.backward()\n","        \n","        \n","        # Clip the norm of the gradients to 1.0.\n","        # This is to help prevent the \"exploding gradients\" problem.\n","        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n","        \n","        \n","        \n","        # Use the optimizer to update the weights.\n","        \n","        # Optimizer for GPU\n","        optimizer.step() \n","        \n","        # Optimizer for TPU\n","        # https://pytorch.org/xla/\n","        #xm.optimizer_step(optimizer, barrier=True)\n","\n","    \n","    print('Train loss:' ,total_train_loss)\n","\n","\n","\n","    # ========================================\n","    #               Validation\n","    # ========================================\n","    \n","    print('\\nValidation...')\n","\n","    # Put the model in evaluation mode.\n","    model.eval()\n","\n","    # Turn off the gradient calculations.\n","    # This tells the model not to compute or store gradients.\n","    # This step saves memory and speeds up validation.\n","    torch.set_grad_enabled(False)\n","    \n","    \n","    # Reset the total loss for this epoch.\n","    total_val_loss = 0\n","    \n","\n","    for j, batch in enumerate(val_dataloader):\n","        \n","        val_status = 'Batch ' + str(j) + ' of ' + str(len(val_dataloader))\n","        \n","        print(val_status, end='\\r')\n","\n","        b_input_ids = batch[0].to(device)\n","        b_input_mask = batch[1].to(device)\n","        b_labels = batch[2].to(device)     \n","\n","\n","        outputs = model(b_input_ids, \n","                attention_mask=b_input_mask, \n","                labels=b_labels)\n","        \n","        # Get the loss from the outputs tuple: (loss, logits)\n","        loss = outputs[0]\n","        \n","        # Convert the loss from a torch tensor to a number.\n","        # Calculate the total loss.\n","        total_val_loss = total_val_loss + loss.item()\n","      \n","\n","\n","\n","        # Get the preds\n","        preds = outputs[1]\n","\n","\n","        # Move preds to the CPU\n","        val_preds = preds.detach().cpu().numpy()\n","        \n","        # Move the labels to the cpu\n","        targets_np = b_labels.to('cpu').numpy()\n","\n","        # Append the labels to a numpy list\n","        targets_list.extend(targets_np)\n","\n","        if j == 0:  # first batch\n","            stacked_val_preds = val_preds\n","        else:\n","            stacked_val_preds = np.vstack((stacked_val_preds, val_preds))\n","\n","    \n","    # Calculate the validation accuracy\n","    y_true = targets_list\n","    y_pred = np.argmax(stacked_val_preds, axis=1)\n","    \n","    val_acc = accuracy_score(y_true, y_pred)\n","    \n","    \n","    print('Val loss:' ,total_val_loss)\n","    print('Val acc: ', val_acc)\n","\n","\n","    # Save the Model\n","    torch.save(model.state_dict(), 'model.pt')\n","    \n","    # Use the garbage collector to save memory.\n","    gc.collect()\n"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"nlpproject","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.8 | packaged by conda-forge | (main, Nov 22 2022, 08:25:29) [Clang 14.0.6 ]"},"vscode":{"interpreter":{"hash":"1963e4c1efbc08bf37151025a3a70fa62b76f4594615bf06e73f232accade162"}}},"nbformat":4,"nbformat_minor":5}
