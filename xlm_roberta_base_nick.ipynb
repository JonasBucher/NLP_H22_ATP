{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":32612,"status":"ok","timestamp":1670676166078,"user":{"displayName":"Dominik Bieri","userId":"16263014991290198195"},"user_tz":-60},"id":"gAPixMnltm20","outputId":"173f7238-185d-45a9-9485-0e494989e01d"},"outputs":[],"source":["!pip install sentencepiece\n","!pip3 install torch torchvision torchaudio\n","!pip install pandas\n","!pip install numpy\n","!pip install scikit-learn\n","!pip install transformers\n","\n","import pandas as pd\n","import numpy as np\n","import os\n","import gc\n","\n","import random\n","\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","from torch.utils.data import Dataset, DataLoader\n","\n","# set a seed value\n","torch.manual_seed(555)\n","\n","from sklearn.utils import shuffle\n","from sklearn.metrics import roc_auc_score, accuracy_score\n","\n","import transformers\n","from transformers import BertTokenizer, BertForSequenceClassification \n","from transformers import XLMRobertaTokenizer, XLMRobertaForSequenceClassification\n","from transformers import AdamW\n","\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n","\n","\n","print(torch.__version__)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1670676918357,"user":{"displayName":"Dominik Bieri","userId":"16263014991290198195"},"user_tz":-60},"id":"7jv2ekewtm22","outputId":"f69492cc-9323-469f-f846-294a1cb1dc67"},"outputs":[],"source":["MODEL_TYPE = 'xlm-roberta-base'\n","\n","\n","L_RATE = 1e-5\n","MAX_LEN = 256\n","\n","NUM_EPOCHS = 20\n","BATCH_SIZE = 32\n","NUM_CORES = os.cpu_count()\n","\n","NUM_CORES"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":422,"status":"ok","timestamp":1670676920382,"user":{"displayName":"Dominik Bieri","userId":"16263014991290198195"},"user_tz":-60},"id":"tHBojRr-BHzr","outputId":"cae94162-d955-4c33-e567-adf6fb4d1695"},"outputs":[],"source":["gpu_info = !nvidia-smi\n","gpu_info = '\\n'.join(gpu_info)\n","if gpu_info.find('failed') >= 0:\n","  print('Not connected to a GPU')\n","else:\n","  print(gpu_info)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1670676920383,"user":{"displayName":"Dominik Bieri","userId":"16263014991290198195"},"user_tz":-60},"id":"SBPPtV38BOYR","outputId":"ca1b53b9-b0f3-4183-e0fe-1faf77fd4a55"},"outputs":[],"source":["from psutil import virtual_memory\n","ram_gb = virtual_memory().total / 1e9\n","print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n","\n","if ram_gb < 20:\n","  print('Not using a high-RAM runtime')\n","else:\n","  print('You are using a high-RAM runtime!')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1670676921609,"user":{"displayName":"Dominik Bieri","userId":"16263014991290198195"},"user_tz":-60},"id":"Ijb985wvBd-6","outputId":"13a6bfab-8a8e-49f1-ab91-3693c4172a37"},"outputs":[],"source":["print(torch.cuda.device_count())"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1670676924676,"user":{"displayName":"Dominik Bieri","userId":"16263014991290198195"},"user_tz":-60},"id":"1LXxd-3bBhON","outputId":"f6f0688c-5049-4610-dc62-f702259c960c"},"outputs":[],"source":["print(torch.cuda.get_device_name(0))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1670676927338,"user":{"displayName":"Dominik Bieri","userId":"16263014991290198195"},"user_tz":-60},"id":"P_vSpen8tm22","outputId":"79a278af-48b4-44af-cb65-26775b35e039"},"outputs":[],"source":["device = torch.device('cuda:0')\n","device"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":1,"status":"ok","timestamp":1670676928659,"user":{"displayName":"Dominik Bieri","userId":"16263014991290198195"},"user_tz":-60},"id":"A2PZE-SvuDT5"},"outputs":[],"source":["#from google.colab import drive\n","#drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1670676929605,"user":{"displayName":"Dominik Bieri","userId":"16263014991290198195"},"user_tz":-60},"id":"6XvCwc2vtm23"},"outputs":[],"source":["df_train=pd.read_csv(\"drive/MyDrive/NLP_Project/data/train.csv\")\n","df_val=pd.read_csv(\"drive/MyDrive/NLP_Project/data/valid.csv\")\n","df_test=pd.read_csv(\"drive/MyDrive/NLP_Project/data/test.csv\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":99,"referenced_widgets":["d720c81f10e24d66944b895c6331318b","b7e9b74baa74475b80a1f37c171c081e","9fd70f1830b34ec1b0f259a36f44573c","4efe93e4e4ee44a8a7982a779de13fb6","9655c783c39b481db9fa037387df1e71","125ea0893a8f47faa73c304903a30bcd","79ba7502360f4f3ba2caac9f7b8d75f2","99f088d92074426fb3a4aedf3257a3ae","464a4750718f43bb8af6a1817256d656","9d2e310babca4694af9b82a88448627a","b2b95ec0d5444d1b916cd719a9638955","dfe5f32f9b07433db7c78e4e4a50601f","0ee47ce480f0424c92c099ac976aa9b5","37280541c1604c7b81cc9b7fbbdbc687","aa47d3d5a5b846ddbd54eb955ed2adb0","f48602341e104661bc9fcd664ef1aed1","a4229d504df64de39eb673adb0f42836","e47d13c7259f48b3ae63fa5e082cb12d","71473e85792a4ef89a70ee7287cd700c","471ea71dff9b45148d7fd9fd696b83f7","919610bfbbbe4b20812b0c0b87df372d","b96f9cd158674aca8c8a9363caf2a473"]},"executionInfo":{"elapsed":3900,"status":"ok","timestamp":1670676195755,"user":{"displayName":"Dominik Bieri","userId":"16263014991290198195"},"user_tz":-60},"id":"o5Srx7KAtm23","outputId":"d8bc7c92-cb30-4b8a-c1d6-ea6af4a555c8"},"outputs":[],"source":["from transformers import XLMRobertaTokenizer, XLMRobertaForSequenceClassification\n","\n","# xlm-roberta-large\n","print('Loading XLMRoberta tokenizer...')\n","tokenizer = XLMRobertaTokenizer.from_pretrained(MODEL_TYPE)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":442,"status":"ok","timestamp":1670676937639,"user":{"displayName":"Dominik Bieri","userId":"16263014991290198195"},"user_tz":-60},"id":"WGYLtM_ftm23"},"outputs":[],"source":["df_train = df_train.reset_index(drop=True)\n","df_val = df_val.reset_index(drop=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":1,"status":"ok","timestamp":1670676940798,"user":{"displayName":"Dominik Bieri","userId":"16263014991290198195"},"user_tz":-60},"id":"Swhu9epptm24"},"outputs":[],"source":["class CompDataset(Dataset):\n","\n","    def __init__(self, df):\n","        self.df_data = df\n","\n","\n","\n","    def __getitem__(self, index):\n","\n","        # get the sentence from the dataframe\n","        sentence1 = self.df_data.loc[index, 'premise']\n","        sentence2 = self.df_data.loc[index, 'hypothesis']\n","\n","        # Process the sentence\n","        # ---------------------\n","\n","        encoded_dict = tokenizer.encode_plus(\n","                    sentence1, sentence2,           # Sentences to encode.\n","                    add_special_tokens = True,      # Add the special tokens.\n","                    max_length = MAX_LEN,           # Pad & truncate all sentences.\n","                    pad_to_max_length = True,\n","                    return_attention_mask = True,   # Construct attn. masks.\n","                    return_tensors = 'pt',          # Return pytorch tensors.\n","               )\n","        \n","        # These are torch tensors.\n","        padded_token_list = encoded_dict['input_ids'][0]\n","        att_mask = encoded_dict['attention_mask'][0]\n","        \n","        # Convert the target to a torch tensor\n","        target = torch.tensor(self.df_data.loc[index, 'label'])\n","\n","        sample = (padded_token_list, att_mask, target)\n","\n","\n","        return sample\n","\n","\n","    def __len__(self):\n","        return len(self.df_data)\n","    \n","\n","class TestDataset(Dataset):\n","\n","    def __init__(self, df):\n","        self.df_data = df\n","\n","\n","\n","    def __getitem__(self, index):\n","\n","        # get the sentence from the dataframe\n","        sentence1 = self.df_data.loc[index, 'premise']\n","        sentence2 = self.df_data.loc[index, 'hypothesis']\n","\n","        # Process the sentence\n","        # ---------------------\n","\n","        encoded_dict = tokenizer.encode_plus(\n","                    sentence1, sentence2,           # Sentence to encode.\n","                    add_special_tokens = True,      # Add the special tokens.\n","                    max_length = MAX_LEN,           # Pad & truncate all sentences.\n","                    pad_to_max_length = True,\n","                    return_attention_mask = True,   # Construct attn. masks.\n","                    return_tensors = 'pt',          # Return pytorch tensors.\n","               )\n","        \n","        # These are torch tensors.\n","        padded_token_list = encoded_dict['input_ids'][0]\n","        att_mask = encoded_dict['attention_mask'][0]\n","        \n","               \n","\n","        sample = (padded_token_list, att_mask)\n","\n","\n","        return sample\n","\n","\n","    def __len__(self):\n","        return len(self.df_data)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1670676940799,"user":{"displayName":"Dominik Bieri","userId":"16263014991290198195"},"user_tz":-60},"id":"vQQ9BJPftm24"},"outputs":[],"source":["df_train = df_train.reset_index(drop=True)\n","df_val = df_val.reset_index(drop=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":404,"status":"ok","timestamp":1670676951292,"user":{"displayName":"Dominik Bieri","userId":"16263014991290198195"},"user_tz":-60},"id":"FHv0E5FGtm25","outputId":"f5f8a648-bdf4-4fdc-e797-d421334249af"},"outputs":[],"source":["df_train = df_train.reset_index(drop=True)\n","df_val = df_val.reset_index(drop=True)\n","train_data = CompDataset(df_train)\n","val_data = CompDataset(df_val)\n","test_data = TestDataset(df_test)\n","\n","\n","train_dataloader = torch.utils.data.DataLoader(train_data,\n","                                        batch_size=BATCH_SIZE,\n","                                        shuffle=True,\n","                                       num_workers=NUM_CORES)\n","\n","val_dataloader = torch.utils.data.DataLoader(val_data,\n","                                        batch_size=BATCH_SIZE,\n","                                        shuffle=True,\n","                                       num_workers=NUM_CORES)\n","\n","test_dataloader = torch.utils.data.DataLoader(test_data,\n","                                        batch_size=BATCH_SIZE,\n","                                        shuffle=False,\n","                                       num_workers=NUM_CORES)\n","\n","\n","print(len(train_dataloader))\n","print(len(val_dataloader))\n","print(len(test_dataloader))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":848,"status":"ok","timestamp":1670676957059,"user":{"displayName":"Dominik Bieri","userId":"16263014991290198195"},"user_tz":-60},"id":"YIZYHrY7tm25","outputId":"68c00b51-61ee-4871-8286-3d6d393ef335"},"outputs":[],"source":["# Get one train batch\n","\n","padded_token_list, att_mask, target = next(iter(train_dataloader))\n","\n","print(padded_token_list.shape)\n","print(att_mask.shape)\n","print(target.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":431,"status":"ok","timestamp":1670676958834,"user":{"displayName":"Dominik Bieri","userId":"16263014991290198195"},"user_tz":-60},"id":"brydhdZVtm25","outputId":"acbf227b-e2bf-4bf3-ef30-c7cf8919a56e"},"outputs":[],"source":["# Get one val batch\n","\n","padded_token_list, att_mask, target = next(iter(val_dataloader))\n","\n","print(padded_token_list.shape)\n","print(att_mask.shape)\n","print(target.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":608,"status":"ok","timestamp":1670676959440,"user":{"displayName":"Dominik Bieri","userId":"16263014991290198195"},"user_tz":-60},"id":"qRCrnPWftm26","outputId":"d446534c-753c-4cde-af58-964f10178f2f"},"outputs":[],"source":["# Get one test batch\n","\n","padded_token_list, att_mask = next(iter(test_dataloader))\n","\n","print(padded_token_list.shape)\n","print(att_mask.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3490,"status":"ok","timestamp":1670676968914,"user":{"displayName":"Dominik Bieri","userId":"16263014991290198195"},"user_tz":-60},"id":"ofiWSvAdtm26","outputId":"fd9a7b11-8ee7-4874-809b-ca2eac6807eb"},"outputs":[],"source":["from transformers import XLMRobertaForSequenceClassification\n","\n","model = XLMRobertaForSequenceClassification.from_pretrained(\n","    MODEL_TYPE, \n","    num_labels = 3, # The number of output labels. 2 for binary classification.\n",")\n","\n","# Send the model to the device.\n","model.to(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1162,"status":"ok","timestamp":1670676971165,"user":{"displayName":"Dominik Bieri","userId":"16263014991290198195"},"user_tz":-60},"id":"zN6Cs-oatm26","outputId":"f8647164-83b1-40bf-a4be-59a5bebcc1ac"},"outputs":[],"source":["# Create a batch of train samples\n","# We will set a small batch size of 8 so that the model's output can be easily displayed.\n","\n","train_dataloader = torch.utils.data.DataLoader(train_data,\n","                                        batch_size=8,\n","                                        shuffle=True,\n","                                       num_workers=NUM_CORES)\n","\n","b_input_ids, b_input_mask, b_labels = next(iter(train_dataloader))\n","\n","print(b_input_ids.shape)\n","print(b_input_mask.shape)\n","print(b_labels.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1031,"status":"ok","timestamp":1670676975260,"user":{"displayName":"Dominik Bieri","userId":"16263014991290198195"},"user_tz":-60},"id":"U85F2z8etm27","outputId":"ccf457a5-7390-4909-d853-56629f77ce17"},"outputs":[],"source":["# Pass a batch of train samples to the model.\n","\n","batch = next(iter(train_dataloader))\n","\n","# Send the data to the device\n","b_input_ids = batch[0].to(device)\n","b_input_mask = batch[1].to(device)\n","b_labels = batch[2].to(device)\n","\n","# Run the model\n","outputs = model(b_input_ids, \n","                        attention_mask=b_input_mask, \n","                        labels=b_labels)\n","\n","# The ouput is a tuple (loss, preds).\n","outputs"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":912,"status":"ok","timestamp":1670676977308,"user":{"displayName":"Dominik Bieri","userId":"16263014991290198195"},"user_tz":-60},"id":"pa4FI0iXtm27","outputId":"e5f6b381-0268-4061-eaaa-23bf9ceb38c0"},"outputs":[],"source":["preds = outputs[1].detach().cpu().numpy()\n","\n","y_true = b_labels.detach().cpu().numpy()\n","y_pred = np.argmax(preds, axis=1)\n","\n","y_pred"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1,"status":"ok","timestamp":1670676979313,"user":{"displayName":"Dominik Bieri","userId":"16263014991290198195"},"user_tz":-60},"id":"T61h0OyRtm27","outputId":"3c20c21f-c818-4dc7-f450-dd9eb910b264"},"outputs":[],"source":["# This is the accuracy without fine tuning.\n","\n","val_acc = accuracy_score(y_true, y_pred)\n","\n","val_acc"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":401,"status":"ok","timestamp":1670676980162,"user":{"displayName":"Dominik Bieri","userId":"16263014991290198195"},"user_tz":-60},"id":"XmyZEX1itm27","outputId":"798a0b8d-5eca-4a77-89d3-64edfbe549da"},"outputs":[],"source":["# The loss and preds are Torch tensors\n","\n","print(type(outputs[0]))\n","print(type(outputs[1]))"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":503,"status":"ok","timestamp":1670676980987,"user":{"displayName":"Dominik Bieri","userId":"16263014991290198195"},"user_tz":-60},"id":"gdtKOQrDtm28"},"outputs":[],"source":["# Define the optimizer\n","optimizer = AdamW(model.parameters(),\n","              lr = L_RATE, \n","              eps = 1e-8 \n","            )"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1670676987342,"user":{"displayName":"Dominik Bieri","userId":"16263014991290198195"},"user_tz":-60},"id":"cLl5oQa5tm28","outputId":"419d6549-2e69-4190-c5fa-b56563874cae"},"outputs":[],"source":["# Create the dataloaders.\n","\n","train_data = CompDataset(df_train)\n","val_data = CompDataset(df_val)\n","test_data = TestDataset(df_test)\n","\n","train_dataloader = torch.utils.data.DataLoader(train_data,\n","                                        batch_size=BATCH_SIZE,\n","                                        shuffle=True,\n","                                       num_workers=NUM_CORES)\n","\n","val_dataloader = torch.utils.data.DataLoader(val_data,\n","                                        batch_size=BATCH_SIZE,\n","                                        shuffle=True,\n","                                       num_workers=NUM_CORES)\n","\n","test_dataloader = torch.utils.data.DataLoader(test_data,\n","                                        batch_size=BATCH_SIZE,\n","                                        shuffle=False,\n","                                       num_workers=NUM_CORES)\n","\n","\n","\n","print(len(train_dataloader))\n","print(len(val_dataloader))\n","print(len(test_dataloader))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UTfZ31NQtm28"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"l4x7Ge8jtm28","outputId":"285c9ac1-a61a-4c23-b8e0-0ee194204cfa"},"outputs":[],"source":["%%time\n","\n","\n","# Set the seed.\n","seed_val = 101\n","\n","random.seed(seed_val)\n","np.random.seed(seed_val)\n","torch.manual_seed(seed_val)\n","torch.cuda.manual_seed_all(seed_val)\n","\n","# Store the average loss after each epoch so we can plot them.\n","loss_values = []\n","\n","\n","# For each epoch...\n","for epoch in range(0, NUM_EPOCHS):\n","    \n","    print(\"\")\n","    print('======== Epoch {:} / {:} ========'.format(epoch + 1, NUM_EPOCHS))\n","    \n","\n","    stacked_val_labels = []\n","    targets_list = []\n","\n","\n","# ========================================\n","    #               Training\n","    # ========================================\n","    \n","    print('Training on ...')\n","    print(model.device)\n","    \n","    # put the model into train mode\n","    model.train()\n","    \n","    # This turns gradient calculations on and off.\n","    torch.set_grad_enabled(True)\n","\n","\n","    # Reset the total loss for this epoch.\n","    total_train_loss = 0\n","\n","    for i, batch in enumerate(train_dataloader):\n","        \n","        train_status = 'Batch ' + str(i) + ' of ' + str(len(train_dataloader))\n","        \n","        print(train_status, end='\\r')\n","\n","\n","        b_input_ids = batch[0].to(device)\n","        b_input_mask = batch[1].to(device)\n","        b_labels = batch[2].to(device)\n","\n","        model.zero_grad()\n","\n","        outputs = model(b_input_ids, \n","                    attention_mask=b_input_mask,\n","                    labels=b_labels)\n","        \n","        # Get the loss from the outputs tuple: (loss, logits)\n","        loss = outputs[0]\n","        \n","        # Convert the loss from a torch tensor to a number.\n","        # Calculate the total loss.\n","        total_train_loss = total_train_loss + loss.item()\n","        \n","        # Zero the gradients\n","        optimizer.zero_grad()\n","        \n","        # Perform a backward pass to calculate the gradients.\n","        loss.backward()\n","        \n","        \n","        # Clip the norm of the gradients to 1.0.\n","        # This is to help prevent the \"exploding gradients\" problem.\n","        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n","        \n","        \n","        \n","        # Use the optimizer to update the weights.\n","        \n","        # Optimizer for GPU\n","        optimizer.step() \n","        \n","        # Optimizer for TPU\n","        # https://pytorch.org/xla/\n","        #xm.optimizer_step(optimizer, barrier=True)\n","\n","    \n","    print('Train loss:' ,total_train_loss)\n","\n","\n","\n","    # ========================================\n","    #               Validation\n","    # ========================================\n","    \n","    print('\\nValidation...')\n","\n","    # Put the model in evaluation mode.\n","    model.eval()\n","\n","    # Turn off the gradient calculations.\n","    # This tells the model not to compute or store gradients.\n","    # This step saves memory and speeds up validation.\n","    torch.set_grad_enabled(False)\n","    \n","    \n","    # Reset the total loss for this epoch.\n","    total_val_loss = 0\n","    \n","\n","    for j, batch in enumerate(val_dataloader):\n","        \n","        val_status = 'Batch ' + str(j) + ' of ' + str(len(val_dataloader))\n","        \n","        print(val_status, end='\\r')\n","\n","        b_input_ids = batch[0].to(device)\n","        b_input_mask = batch[1].to(device)\n","        b_labels = batch[2].to(device)     \n","\n","\n","        outputs = model(b_input_ids, \n","                attention_mask=b_input_mask, \n","                labels=b_labels)\n","        \n","        # Get the loss from the outputs tuple: (loss, logits)\n","        loss = outputs[0]\n","        \n","        # Convert the loss from a torch tensor to a number.\n","        # Calculate the total loss.\n","        total_val_loss = total_val_loss + loss.item()\n","        \n","\n","        # Get the preds\n","        preds = outputs[1]\n","\n","\n","        # Move preds to the CPU\n","        val_preds = preds.detach().cpu().numpy()\n","        \n","        # Move the labels to the cpu\n","        targets_np = b_labels.to('cpu').numpy()\n","\n","        # Append the labels to a numpy list\n","        targets_list.extend(targets_np)\n","\n","        if j == 0:  # first batch\n","            stacked_val_preds = val_preds\n","        else:\n","            stacked_val_preds = np.vstack((stacked_val_preds, val_preds))\n","\n","    \n","    # Calculate the validation accuracy\n","    y_true = targets_list\n","    y_pred = np.argmax(stacked_val_preds, axis=1)\n","    \n","    val_acc = accuracy_score(y_true, y_pred)\n","    \n","    \n","    print('Val loss:' ,total_val_loss)\n","    print('Val acc: ', val_acc)\n","\n","\n","    # Save the Model\n","    torch.save(model.state_dict(), 'model.pt')\n","    \n","    # Use the garbage collector to save memory.\n","    gc.collect()"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1670676812045,"user":{"displayName":"Dominik Bieri","userId":"16263014991290198195"},"user_tz":-60},"id":"Shqyt17zC-L4"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"machine_shape":"hm","provenance":[]},"gpuClass":"premium","kernelspec":{"display_name":"nlpproject","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.8 | packaged by conda-forge | (main, Nov 22 2022, 08:25:29) [Clang 14.0.6 ]"},"orig_nbformat":4,"vscode":{"interpreter":{"hash":"1963e4c1efbc08bf37151025a3a70fa62b76f4594615bf06e73f232accade162"}},"widgets":{"application/vnd.jupyter.widget-state+json":{"0ee47ce480f0424c92c099ac976aa9b5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a4229d504df64de39eb673adb0f42836","placeholder":"​","style":"IPY_MODEL_e47d13c7259f48b3ae63fa5e082cb12d","value":"Downloading: 100%"}},"125ea0893a8f47faa73c304903a30bcd":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"37280541c1604c7b81cc9b7fbbdbc687":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_71473e85792a4ef89a70ee7287cd700c","max":615,"min":0,"orientation":"horizontal","style":"IPY_MODEL_471ea71dff9b45148d7fd9fd696b83f7","value":615}},"464a4750718f43bb8af6a1817256d656":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"471ea71dff9b45148d7fd9fd696b83f7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"4efe93e4e4ee44a8a7982a779de13fb6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9d2e310babca4694af9b82a88448627a","placeholder":"​","style":"IPY_MODEL_b2b95ec0d5444d1b916cd719a9638955","value":" 5.07M/5.07M [00:00&lt;00:00, 6.76MB/s]"}},"71473e85792a4ef89a70ee7287cd700c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"79ba7502360f4f3ba2caac9f7b8d75f2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"919610bfbbbe4b20812b0c0b87df372d":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9655c783c39b481db9fa037387df1e71":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"99f088d92074426fb3a4aedf3257a3ae":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9d2e310babca4694af9b82a88448627a":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9fd70f1830b34ec1b0f259a36f44573c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_99f088d92074426fb3a4aedf3257a3ae","max":5069051,"min":0,"orientation":"horizontal","style":"IPY_MODEL_464a4750718f43bb8af6a1817256d656","value":5069051}},"a4229d504df64de39eb673adb0f42836":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"aa47d3d5a5b846ddbd54eb955ed2adb0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_919610bfbbbe4b20812b0c0b87df372d","placeholder":"​","style":"IPY_MODEL_b96f9cd158674aca8c8a9363caf2a473","value":" 615/615 [00:00&lt;00:00, 26.2kB/s]"}},"b2b95ec0d5444d1b916cd719a9638955":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b7e9b74baa74475b80a1f37c171c081e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_125ea0893a8f47faa73c304903a30bcd","placeholder":"​","style":"IPY_MODEL_79ba7502360f4f3ba2caac9f7b8d75f2","value":"Downloading: 100%"}},"b96f9cd158674aca8c8a9363caf2a473":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d720c81f10e24d66944b895c6331318b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b7e9b74baa74475b80a1f37c171c081e","IPY_MODEL_9fd70f1830b34ec1b0f259a36f44573c","IPY_MODEL_4efe93e4e4ee44a8a7982a779de13fb6"],"layout":"IPY_MODEL_9655c783c39b481db9fa037387df1e71"}},"dfe5f32f9b07433db7c78e4e4a50601f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_0ee47ce480f0424c92c099ac976aa9b5","IPY_MODEL_37280541c1604c7b81cc9b7fbbdbc687","IPY_MODEL_aa47d3d5a5b846ddbd54eb955ed2adb0"],"layout":"IPY_MODEL_f48602341e104661bc9fcd664ef1aed1"}},"e47d13c7259f48b3ae63fa5e082cb12d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f48602341e104661bc9fcd664ef1aed1":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}}}}},"nbformat":4,"nbformat_minor":0}
